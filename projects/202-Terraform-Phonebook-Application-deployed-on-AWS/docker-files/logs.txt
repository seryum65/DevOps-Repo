* 
* ==> Audit <==
* |--------------|--------------------------------|----------|----------|---------|---------------------|---------------------|
|   Command    |              Args              | Profile  |   User   | Version |     Start Time      |      End Time       |
|--------------|--------------------------------|----------|----------|---------|---------------------|---------------------|
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:47 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:47 +03 |                     |
| start        | --driver=docker                | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:49 +03 |                     |
| config       | set driver docker              | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:49 +03 | 09 Aug 22 11:49 +03 |
| start        | --driver=kvm2                  | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:50 +03 |                     |
| start        | --driver=virtualbox            | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:50 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:51 +03 |                     |
| kubectl      | -- get po -A                   | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:52 +03 |                     |
| kubectl      | -- get po -A                   | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:52 +03 |                     |
| kubectl      | -- get po -A                   | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:54 +03 |                     |
| kubectl      | -- get po -A                   | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:54 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:54 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 11:54 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:08 +03 |                     |
| kubectl      | get nodes                      | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:10 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:13 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:15 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:15 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:20 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:21 +03 |                     |
| start        | --driver=none                  | minikube | root     | v1.26.1 | 09 Aug 22 12:22 +03 |                     |
| start        | --driver=podman                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:23 +03 |                     |
|              | --container-runtime=cri-o      |          |          |         |                     |                     |
| start        | --driver=docker                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:23 +03 |                     |
| config       | set driver docker              | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:23 +03 | 09 Aug 22 12:23 +03 |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:24 +03 |                     |
| dashboard    |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:25 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:25 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:26 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:28 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 12:29 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 14:25 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 14:54 +03 | 09 Aug 22 14:57 +03 |
| dashboard    |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 14:58 +03 |                     |
| update-check |                                | minikube | seryum65 | v1.26.1 | 09 Aug 22 15:35 +03 | 09 Aug 22 15:35 +03 |
| update-check |                                | minikube | seryum65 | v1.26.1 | 10 Aug 22 09:07 +03 | 10 Aug 22 09:07 +03 |
| start        |                                | minikube | seryum65 | v1.26.1 | 10 Aug 22 09:57 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 10 Aug 22 10:09 +03 | 10 Aug 22 10:12 +03 |
| ssh          | -- docker system prune         | minikube | seryum65 | v1.26.1 | 10 Aug 22 10:19 +03 | 10 Aug 22 10:19 +03 |
| stop         |                                | minikube | seryum65 | v1.26.1 | 10 Aug 22 11:38 +03 | 10 Aug 22 11:39 +03 |
| stop         |                                | minikube | seryum65 | v1.26.1 | 10 Aug 22 15:19 +03 |                     |
| start        |                                | minikube | seryum65 | v1.26.1 | 10 Aug 22 15:37 +03 |                     |
|--------------|--------------------------------|----------|----------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2022/08/10 15:37:00
Running on machine: yusuf
Binary: Built with gc go1.18.3 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0810 15:37:00.491916   97653 out.go:296] Setting OutFile to fd 1 ...
I0810 15:37:00.492077   97653 out.go:348] isatty.IsTerminal(1) = true
I0810 15:37:00.492081   97653 out.go:309] Setting ErrFile to fd 2...
I0810 15:37:00.492088   97653 out.go:348] isatty.IsTerminal(2) = true
I0810 15:37:00.492206   97653 root.go:333] Updating PATH: /home/seryum65/.minikube/bin
I0810 15:37:00.492841   97653 out.go:303] Setting JSON to false
I0810 15:37:00.512968   97653 start.go:115] hostinfo: {"hostname":"yusuf","uptime":25700,"bootTime":1660109320,"procs":277,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"20.04","kernelVersion":"5.15.0-43-generic","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"dea1cbd0-ecd3-4555-8af3-be83b7283047"}
I0810 15:37:00.513038   97653 start.go:125] virtualization:  
I0810 15:37:00.524371   97653 out.go:177] üòÑ  minikube v1.26.1 on Ubuntu 20.04
I0810 15:37:00.549191   97653 notify.go:193] Checking for updates...
I0810 15:37:00.550259   97653 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0810 15:37:00.552406   97653 driver.go:365] Setting default libvirt URI to qemu:///system
I0810 15:37:00.619214   97653 docker.go:137] docker version: linux-20.10.17
I0810 15:37:00.619303   97653 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0810 15:37:00.711197   97653 info.go:265] docker info: {ID:T6BO:EHAH:HVNQ:2DT6:2T3G:FGJY:NTSH:OP3U:4EYD:6BNE:TUAF:2S53 Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:13 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:33 SystemTime:2022-08-10 15:37:00.648532041 +0300 +03 LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:5.15.0-43-generic OperatingSystem:Ubuntu 20.04.4 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8212738048 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:yusuf Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb Expected:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb} RuncCommit:{ID:v1.1.3-0-g6724737 Expected:v1.1.3-0-g6724737} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=default] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Experimental:true Name:app Path:/usr/libexec/docker/cli-plugins/docker-app SchemaVersion:0.1.0 ShortDescription:Docker App Vendor:Docker Inc. Version:v0.9.1-beta3] map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2-docker] map[Name:scan Path:/usr/libexec/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0810 15:37:00.711334   97653 docker.go:254] overlay module found
I0810 15:37:00.722035   97653 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0810 15:37:00.730149   97653 start.go:284] selected driver: docker
I0810 15:37:00.730159   97653 start.go:808] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/seryum65:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0810 15:37:00.730321   97653 start.go:819] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0810 15:37:00.730425   97653 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0810 15:37:00.834548   97653 info.go:265] docker info: {ID:T6BO:EHAH:HVNQ:2DT6:2T3G:FGJY:NTSH:OP3U:4EYD:6BNE:TUAF:2S53 Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:13 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:33 SystemTime:2022-08-10 15:37:00.762054238 +0300 +03 LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:5.15.0-43-generic OperatingSystem:Ubuntu 20.04.4 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8212738048 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:yusuf Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb Expected:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb} RuncCommit:{ID:v1.1.3-0-g6724737 Expected:v1.1.3-0-g6724737} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=default] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Experimental:true Name:app Path:/usr/libexec/docker/cli-plugins/docker-app SchemaVersion:0.1.0 ShortDescription:Docker App Vendor:Docker Inc. Version:v0.9.1-beta3] map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2-docker] map[Name:scan Path:/usr/libexec/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0810 15:37:00.835121   97653 cni.go:95] Creating CNI manager for ""
I0810 15:37:00.835132   97653 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0810 15:37:00.835137   97653 start_flags.go:310] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/seryum65:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0810 15:37:00.842244   97653 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0810 15:37:00.855573   97653 cache.go:120] Beginning downloading kic base image for docker with docker
I0810 15:37:00.866115   97653 out.go:177] üöú  Pulling base image ...
I0810 15:37:00.886740   97653 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon
I0810 15:37:00.886742   97653 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0810 15:37:00.886806   97653 preload.go:148] Found local preload: /home/seryum65/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4
I0810 15:37:00.886813   97653 cache.go:57] Caching tarball of preloaded images
I0810 15:37:00.887041   97653 preload.go:174] Found /home/seryum65/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0810 15:37:00.887053   97653 cache.go:60] Finished verifying existence of preloaded tar for  v1.24.3 on docker
I0810 15:37:00.887222   97653 profile.go:148] Saving config to /home/seryum65/.minikube/profiles/minikube/config.json ...
I0810 15:37:00.932336   97653 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon, skipping pull
I0810 15:37:00.932353   97653 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 exists in daemon, skipping load
I0810 15:37:00.932369   97653 cache.go:208] Successfully downloaded all kic artifacts
I0810 15:37:00.932410   97653 start.go:371] acquiring machines lock for minikube: {Name:mkf734f0a03855166c67a9a3cea542e99890d087 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0810 15:37:00.932550   97653 start.go:375] acquired machines lock for "minikube" in 112.517¬µs
I0810 15:37:00.932567   97653 start.go:95] Skipping create...Using existing machine configuration
I0810 15:37:00.932572   97653 fix.go:55] fixHost starting: 
I0810 15:37:00.932887   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:00.989085   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:00.989148   97653 fix.go:103] recreateIfNeeded on minikube: state= err=unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:00.989162   97653 fix.go:108] machineExists: false. err=machine does not exist
I0810 15:37:01.000053   97653 out.go:177] ü§∑  docker "minikube" container is missing, will recreate.
I0810 15:37:01.011917   97653 delete.go:124] DEMOLISHING minikube ...
I0810 15:37:01.012027   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:01.050181   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
W0810 15:37:01.050214   97653 stop.go:75] unable to get state: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:01.050230   97653 delete.go:129] stophost failed (probably ok): ssh power off: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:01.050615   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:01.094326   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:01.094394   97653 delete.go:82] Unable to get host status for minikube, assuming it has already been deleted: state: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:01.094456   97653 cli_runner.go:164] Run: docker container inspect -f {{.Id}} minikube
W0810 15:37:01.125418   97653 cli_runner.go:211] docker container inspect -f {{.Id}} minikube returned with exit code 1
I0810 15:37:01.125432   97653 kic.go:356] could not find the container minikube to remove it. will try anyways
I0810 15:37:01.125488   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:01.157537   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
W0810 15:37:01.157591   97653 oci.go:84] error getting container status, will try to delete anyways: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:01.157633   97653 cli_runner.go:164] Run: docker exec --privileged -t minikube /bin/bash -c "sudo init 0"
W0810 15:37:01.187657   97653 cli_runner.go:211] docker exec --privileged -t minikube /bin/bash -c "sudo init 0" returned with exit code 1
I0810 15:37:01.187674   97653 oci.go:646] error shutdown minikube: docker exec --privileged -t minikube /bin/bash -c "sudo init 0": exit status 1
stdout:

stderr:
Error: No such container: minikube
I0810 15:37:02.187990   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:02.252187   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:02.252233   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:02.252241   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:02.252280   97653 retry.go:31] will retry after 552.330144ms: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:02.805299   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:02.878075   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:02.878116   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:02.878131   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:02.878155   97653 retry.go:31] will retry after 1.080381816s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:03.959467   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:04.014654   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:04.014723   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:04.014739   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:04.014763   97653 retry.go:31] will retry after 1.31013006s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:05.326463   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:05.363630   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:05.363663   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:05.363669   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:05.363687   97653 retry.go:31] will retry after 1.582392691s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:06.947810   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:06.986318   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:06.986358   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:06.986363   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:06.986381   97653 retry.go:31] will retry after 2.340488664s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:09.327515   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:09.365068   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:09.365109   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:09.365116   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:09.365137   97653 retry.go:31] will retry after 4.506218855s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:13.874339   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:13.933180   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:13.933236   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:13.933241   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:13.933260   97653 retry.go:31] will retry after 3.221479586s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:17.156099   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:17.252895   97653 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0810 15:37:17.252939   97653 oci.go:658] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
I0810 15:37:17.252948   97653 oci.go:660] temporary error: container minikube status is  but expect it to be exited
I0810 15:37:17.252988   97653 oci.go:88] couldn't shut down minikube (might be okay): verify shutdown: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error: No such container: minikube
 
I0810 15:37:17.253084   97653 cli_runner.go:164] Run: docker rm -f -v minikube
I0810 15:37:17.299755   97653 cli_runner.go:164] Run: docker container inspect -f {{.Id}} minikube
W0810 15:37:17.340181   97653 cli_runner.go:211] docker container inspect -f {{.Id}} minikube returned with exit code 1
I0810 15:37:17.340275   97653 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0810 15:37:17.380595   97653 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0810 15:37:17.380671   97653 network_create.go:272] running [docker network inspect minikube] to gather additional debugging logs...
I0810 15:37:17.380688   97653 cli_runner.go:164] Run: docker network inspect minikube
W0810 15:37:17.420220   97653 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0810 15:37:17.420236   97653 network_create.go:275] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error: No such network: minikube
I0810 15:37:17.420250   97653 network_create.go:277] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error: No such network: minikube

** /stderr **
W0810 15:37:17.422267   97653 delete.go:139] delete failed (probably ok) <nil>
I0810 15:37:17.422276   97653 fix.go:115] Sleeping 1 second for extra luck!
I0810 15:37:18.422398   97653 start.go:132] createHost starting for "" (driver="docker")
I0810 15:37:18.448923   97653 out.go:204] üî•  Creating docker container (CPUs=2, Memory=2200MB) ...
I0810 15:37:18.450950   97653 start.go:166] libmachine.API.Create for "minikube" (driver="docker")
I0810 15:37:18.450990   97653 client.go:168] LocalClient.Create starting
I0810 15:37:18.451135   97653 main.go:134] libmachine: Reading certificate data from /home/seryum65/.minikube/certs/ca.pem
I0810 15:37:18.451458   97653 main.go:134] libmachine: Decoding PEM data...
I0810 15:37:18.451495   97653 main.go:134] libmachine: Parsing certificate...
I0810 15:37:18.451648   97653 main.go:134] libmachine: Reading certificate data from /home/seryum65/.minikube/certs/cert.pem
I0810 15:37:18.451715   97653 main.go:134] libmachine: Decoding PEM data...
I0810 15:37:18.451738   97653 main.go:134] libmachine: Parsing certificate...
I0810 15:37:18.452106   97653 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0810 15:37:18.521196   97653 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0810 15:37:18.521297   97653 network_create.go:272] running [docker network inspect minikube] to gather additional debugging logs...
I0810 15:37:18.521314   97653 cli_runner.go:164] Run: docker network inspect minikube
W0810 15:37:18.624195   97653 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0810 15:37:18.624215   97653 network_create.go:275] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error: No such network: minikube
I0810 15:37:18.624227   97653 network_create.go:277] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error: No such network: minikube

** /stderr **
I0810 15:37:18.624285   97653 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0810 15:37:18.739943   97653 network.go:288] reserving subnet 192.168.49.0 for 1m0s: &{mu:{state:0 sema:0} read:{v:{m:map[] amended:true}} dirty:map[192.168.49.0:0xc000010d80] misses:0}
I0810 15:37:18.741637   97653 network.go:235] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:}}
I0810 15:37:18.741725   97653 network_create.go:115] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 1500 ...
I0810 15:37:18.741864   97653 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0810 15:37:18.898862   97653 network_create.go:99] docker network minikube 192.168.49.0/24 created
I0810 15:37:18.898883   97653 kic.go:106] calculated static IP "192.168.49.2" for the "minikube" container
I0810 15:37:18.898980   97653 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0810 15:37:18.974103   97653 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0810 15:37:19.051476   97653 oci.go:103] Successfully created a docker volume minikube
I0810 15:37:19.051554   97653 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib
I0810 15:37:20.232710   97653 cli_runner.go:217] Completed: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib: (1.181122777s)
I0810 15:37:20.232738   97653 oci.go:107] Successfully prepared a docker volume minikube
I0810 15:37:20.232777   97653 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0810 15:37:20.232793   97653 kic.go:179] Starting extracting preloaded images to volume ...
I0810 15:37:20.232859   97653 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v /home/seryum65/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir
I0810 15:37:28.346470   97653 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v /home/seryum65/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir: (8.113536828s)
I0810 15:37:28.346507   97653 kic.go:188] duration metric: took 8.113703 seconds to extract preloaded images to volume
W0810 15:37:28.347274   97653 cgroups_linux.go:77] Your kernel does not support swap limit capabilities or the cgroup is not mounted.
I0810 15:37:28.347477   97653 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0810 15:37:28.491124   97653 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8
I0810 15:37:29.377279   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0810 15:37:29.416487   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0810 15:37:29.469910   97653 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0810 15:37:29.671127   97653 oci.go:144] the created container "minikube" has a running status.
I0810 15:37:29.671309   97653 kic.go:210] Creating ssh key for kic: /home/seryum65/.minikube/machines/minikube/id_rsa...
I0810 15:37:30.107825   97653 kic_runner.go:191] docker (temp): /home/seryum65/.minikube/machines/minikube/id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0810 15:37:30.306234   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0810 15:37:30.385374   97653 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0810 15:37:30.385391   97653 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0810 15:37:30.511825   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0810 15:37:30.555894   97653 machine.go:88] provisioning docker machine ...
I0810 15:37:30.555918   97653 ubuntu.go:169] provisioning hostname "minikube"
I0810 15:37:30.555994   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:30.598063   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:30.598248   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:30.598258   97653 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0810 15:37:30.598782   97653 main.go:134] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:48718->127.0.0.1:49157: read: connection reset by peer
I0810 15:37:33.600756   97653 main.go:134] libmachine: Error dialing TCP: ssh: handshake failed: EOF
I0810 15:37:36.790394   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0810 15:37:36.790471   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:36.871442   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:36.871673   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:36.871705   97653 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0810 15:37:37.050378   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0810 15:37:37.050425   97653 ubuntu.go:175] set auth options {CertDir:/home/seryum65/.minikube CaCertPath:/home/seryum65/.minikube/certs/ca.pem CaPrivateKeyPath:/home/seryum65/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/seryum65/.minikube/machines/server.pem ServerKeyPath:/home/seryum65/.minikube/machines/server-key.pem ClientKeyPath:/home/seryum65/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/seryum65/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/seryum65/.minikube}
I0810 15:37:37.050530   97653 ubuntu.go:177] setting up certificates
I0810 15:37:37.050566   97653 provision.go:83] configureAuth start
I0810 15:37:37.050771   97653 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0810 15:37:37.162379   97653 provision.go:138] copyHostCerts
I0810 15:37:37.162522   97653 exec_runner.go:144] found /home/seryum65/.minikube/key.pem, removing ...
I0810 15:37:37.162534   97653 exec_runner.go:207] rm: /home/seryum65/.minikube/key.pem
I0810 15:37:37.162652   97653 exec_runner.go:151] cp: /home/seryum65/.minikube/certs/key.pem --> /home/seryum65/.minikube/key.pem (1675 bytes)
I0810 15:37:37.163086   97653 exec_runner.go:144] found /home/seryum65/.minikube/ca.pem, removing ...
I0810 15:37:37.163103   97653 exec_runner.go:207] rm: /home/seryum65/.minikube/ca.pem
I0810 15:37:37.163221   97653 exec_runner.go:151] cp: /home/seryum65/.minikube/certs/ca.pem --> /home/seryum65/.minikube/ca.pem (1082 bytes)
I0810 15:37:37.163391   97653 exec_runner.go:144] found /home/seryum65/.minikube/cert.pem, removing ...
I0810 15:37:37.163420   97653 exec_runner.go:207] rm: /home/seryum65/.minikube/cert.pem
I0810 15:37:37.163483   97653 exec_runner.go:151] cp: /home/seryum65/.minikube/certs/cert.pem --> /home/seryum65/.minikube/cert.pem (1127 bytes)
I0810 15:37:37.163593   97653 provision.go:112] generating server cert: /home/seryum65/.minikube/machines/server.pem ca-key=/home/seryum65/.minikube/certs/ca.pem private-key=/home/seryum65/.minikube/certs/ca-key.pem org=seryum65.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0810 15:37:37.276508   97653 provision.go:172] copyRemoteCerts
I0810 15:37:37.277818   97653 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0810 15:37:37.277922   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:37.324291   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:37.447902   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0810 15:37:37.520069   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/machines/server.pem --> /etc/docker/server.pem (1208 bytes)
I0810 15:37:37.579220   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0810 15:37:37.608533   97653 provision.go:86] duration metric: configureAuth took 557.925664ms
I0810 15:37:37.608588   97653 ubuntu.go:193] setting minikube options for container-runtime
I0810 15:37:37.609246   97653 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0810 15:37:37.609444   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:37.749317   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:37.749518   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:37.749532   97653 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0810 15:37:37.936626   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0810 15:37:37.936639   97653 ubuntu.go:71] root file system type: overlay
I0810 15:37:37.936776   97653 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0810 15:37:37.936829   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:38.099335   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:38.099932   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:38.100082   97653 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0810 15:37:38.293840   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0810 15:37:38.293955   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:38.348399   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:38.348547   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:38.348561   97653 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0810 15:37:39.769330   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2022-06-06 23:01:03.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2022-08-10 12:37:38.286073920 +0000
@@ -1,30 +1,32 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
 Wants=network-online.target
-Requires=docker.socket containerd.service
+Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutSec=0
-RestartSec=2
-Restart=always
-
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
+Restart=on-failure
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +34,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0810 15:37:39.769354   97653 machine.go:91] provisioned docker machine in 9.213449065s
I0810 15:37:39.769365   97653 client.go:171] LocalClient.Create took 21.318367591s
I0810 15:37:39.769376   97653 start.go:174] duration metric: libmachine.API.Create for "minikube" took 21.318430379s
I0810 15:37:39.769383   97653 start.go:307] post-start starting for "minikube" (driver="docker")
I0810 15:37:39.769392   97653 start.go:335] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0810 15:37:39.769466   97653 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0810 15:37:39.769526   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:39.817335   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:39.915826   97653 ssh_runner.go:195] Run: cat /etc/os-release
I0810 15:37:39.919472   97653 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0810 15:37:39.919486   97653 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0810 15:37:39.919495   97653 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0810 15:37:39.919501   97653 info.go:137] Remote host: Ubuntu 20.04.4 LTS
I0810 15:37:39.919511   97653 filesync.go:126] Scanning /home/seryum65/.minikube/addons for local assets ...
I0810 15:37:39.919576   97653 filesync.go:126] Scanning /home/seryum65/.minikube/files for local assets ...
I0810 15:37:39.919846   97653 start.go:310] post-start completed in 150.457553ms
I0810 15:37:39.920164   97653 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0810 15:37:39.987644   97653 profile.go:148] Saving config to /home/seryum65/.minikube/profiles/minikube/config.json ...
I0810 15:37:39.988040   97653 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0810 15:37:39.988090   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:40.032044   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:40.128500   97653 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0810 15:37:40.139973   97653 start.go:135] duration metric: createHost completed in 21.717555634s
I0810 15:37:40.140115   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0810 15:37:40.211843   97653 fix.go:129] unexpected machine state, will restart: <nil>
I0810 15:37:40.211859   97653 machine.go:88] provisioning docker machine ...
I0810 15:37:40.211883   97653 ubuntu.go:169] provisioning hostname "minikube"
I0810 15:37:40.211978   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:40.298600   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:40.298805   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:40.298815   97653 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0810 15:37:40.448227   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0810 15:37:40.448343   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:40.513237   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:40.513478   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:40.513500   97653 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0810 15:37:40.682926   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0810 15:37:40.682982   97653 ubuntu.go:175] set auth options {CertDir:/home/seryum65/.minikube CaCertPath:/home/seryum65/.minikube/certs/ca.pem CaPrivateKeyPath:/home/seryum65/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/seryum65/.minikube/machines/server.pem ServerKeyPath:/home/seryum65/.minikube/machines/server-key.pem ClientKeyPath:/home/seryum65/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/seryum65/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/seryum65/.minikube}
I0810 15:37:40.683008   97653 ubuntu.go:177] setting up certificates
I0810 15:37:40.683020   97653 provision.go:83] configureAuth start
I0810 15:37:40.683144   97653 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0810 15:37:40.730691   97653 provision.go:138] copyHostCerts
I0810 15:37:40.730758   97653 exec_runner.go:144] found /home/seryum65/.minikube/ca.pem, removing ...
I0810 15:37:40.730766   97653 exec_runner.go:207] rm: /home/seryum65/.minikube/ca.pem
I0810 15:37:40.730850   97653 exec_runner.go:151] cp: /home/seryum65/.minikube/certs/ca.pem --> /home/seryum65/.minikube/ca.pem (1082 bytes)
I0810 15:37:40.730962   97653 exec_runner.go:144] found /home/seryum65/.minikube/cert.pem, removing ...
I0810 15:37:40.730968   97653 exec_runner.go:207] rm: /home/seryum65/.minikube/cert.pem
I0810 15:37:40.731005   97653 exec_runner.go:151] cp: /home/seryum65/.minikube/certs/cert.pem --> /home/seryum65/.minikube/cert.pem (1127 bytes)
I0810 15:37:40.731119   97653 exec_runner.go:144] found /home/seryum65/.minikube/key.pem, removing ...
I0810 15:37:40.731123   97653 exec_runner.go:207] rm: /home/seryum65/.minikube/key.pem
I0810 15:37:40.731152   97653 exec_runner.go:151] cp: /home/seryum65/.minikube/certs/key.pem --> /home/seryum65/.minikube/key.pem (1675 bytes)
I0810 15:37:40.731282   97653 provision.go:112] generating server cert: /home/seryum65/.minikube/machines/server.pem ca-key=/home/seryum65/.minikube/certs/ca.pem private-key=/home/seryum65/.minikube/certs/ca-key.pem org=seryum65.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0810 15:37:40.956465   97653 provision.go:172] copyRemoteCerts
I0810 15:37:40.956525   97653 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0810 15:37:40.956566   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:40.992408   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:41.097679   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0810 15:37:41.127416   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/machines/server.pem --> /etc/docker/server.pem (1204 bytes)
I0810 15:37:41.157208   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0810 15:37:41.186876   97653 provision.go:86] duration metric: configureAuth took 503.84744ms
I0810 15:37:41.186892   97653 ubuntu.go:193] setting minikube options for container-runtime
I0810 15:37:41.187171   97653 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0810 15:37:41.187235   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:41.222247   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:41.222380   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:41.222391   97653 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0810 15:37:41.356047   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0810 15:37:41.356061   97653 ubuntu.go:71] root file system type: overlay
I0810 15:37:41.356331   97653 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0810 15:37:41.356478   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:41.410036   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:41.410228   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:41.410323   97653 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0810 15:37:41.583777   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0810 15:37:41.583886   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:41.642484   97653 main.go:134] libmachine: Using SSH client type: native
I0810 15:37:41.642703   97653 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7daec0] 0x7ddf20 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0810 15:37:41.642730   97653 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0810 15:37:41.802823   97653 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0810 15:37:41.802834   97653 machine.go:91] provisioned docker machine in 1.590969614s
I0810 15:37:41.802841   97653 start.go:307] post-start starting for "minikube" (driver="docker")
I0810 15:37:41.802846   97653 start.go:335] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0810 15:37:41.802923   97653 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0810 15:37:41.802966   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:41.851682   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:41.989195   97653 ssh_runner.go:195] Run: cat /etc/os-release
I0810 15:37:42.022333   97653 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0810 15:37:42.022433   97653 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0810 15:37:42.022519   97653 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0810 15:37:42.022570   97653 info.go:137] Remote host: Ubuntu 20.04.4 LTS
I0810 15:37:42.022611   97653 filesync.go:126] Scanning /home/seryum65/.minikube/addons for local assets ...
I0810 15:37:42.022860   97653 filesync.go:126] Scanning /home/seryum65/.minikube/files for local assets ...
I0810 15:37:42.022973   97653 start.go:310] post-start completed in 220.113479ms
I0810 15:37:42.023173   97653 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0810 15:37:42.023385   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:42.114352   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:42.214819   97653 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0810 15:37:42.221966   97653 fix.go:57] fixHost completed within 41.289386564s
I0810 15:37:42.221980   97653 start.go:82] releasing machines lock for "minikube", held for 41.289421563s
I0810 15:37:42.222107   97653 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0810 15:37:42.297285   97653 ssh_runner.go:195] Run: systemctl --version
I0810 15:37:42.297347   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:42.301751   97653 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0810 15:37:42.301930   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:37:42.389014   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:42.487366   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:37:42.501128   97653 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0810 15:37:42.519307   97653 cruntime.go:273] skipping containerd shutdown because we are bound to it
I0810 15:37:42.519375   97653 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0810 15:37:42.538483   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0810 15:37:43.041009   97653 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0810 15:37:43.196842   97653 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0810 15:37:43.391473   97653 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0810 15:37:43.534205   97653 ssh_runner.go:195] Run: sudo systemctl restart docker
I0810 15:37:44.343723   97653 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0810 15:37:44.462879   97653 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0810 15:37:44.664812   97653 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0810 15:37:44.693681   97653 start.go:450] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0810 15:37:44.693831   97653 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0810 15:37:44.700628   97653 start.go:471] Will wait 60s for crictl version
I0810 15:37:44.700684   97653 ssh_runner.go:195] Run: sudo crictl version
I0810 15:37:45.156855   97653 start.go:480] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.17
RuntimeApiVersion:  1.41.0
I0810 15:37:45.156906   97653 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0810 15:37:45.465350   97653 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0810 15:37:45.562918   97653 out.go:204] üê≥  Preparing Kubernetes v1.24.3 on Docker 20.10.17 ...
I0810 15:37:45.564756   97653 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0810 15:37:45.637197   97653 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I0810 15:37:45.641333   97653 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.49.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0810 15:37:45.660181   97653 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0810 15:37:45.660247   97653 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0810 15:37:45.716347   97653 docker.go:611] Got preloaded images: -- stdout --
<none>:<none>
k8s.gcr.io/kube-apiserver:v1.24.3
k8s.gcr.io/kube-scheduler:v1.24.3
k8s.gcr.io/kube-proxy:v1.24.3
k8s.gcr.io/kube-controller-manager:v1.24.3
<none>:<none>
<none>:<none>
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/pause:3.7
k8s.gcr.io/coredns/coredns:v1.8.6
<none>:<none>
<none>:<none>
gcr.io/k8s-minikube/storage-provisioner:v5
<none>:<none>

-- /stdout --
I0810 15:37:45.716364   97653 docker.go:542] Images already preloaded, skipping extraction
I0810 15:37:45.716423   97653 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0810 15:37:45.757456   97653 docker.go:611] Got preloaded images: -- stdout --
<none>:<none>
k8s.gcr.io/kube-apiserver:v1.24.3
k8s.gcr.io/kube-scheduler:v1.24.3
k8s.gcr.io/kube-controller-manager:v1.24.3
k8s.gcr.io/kube-proxy:v1.24.3
<none>:<none>
<none>:<none>
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/pause:3.7
k8s.gcr.io/coredns/coredns:v1.8.6
<none>:<none>
<none>:<none>
gcr.io/k8s-minikube/storage-provisioner:v5
<none>:<none>

-- /stdout --
I0810 15:37:45.757467   97653 cache_images.go:84] Images are preloaded, skipping loading
I0810 15:37:45.757526   97653 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0810 15:37:46.168091   97653 cni.go:95] Creating CNI manager for ""
I0810 15:37:46.168101   97653 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0810 15:37:46.168113   97653 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0810 15:37:46.168124   97653 kubeadm.go:158] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.24.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I0810 15:37:46.168224   97653 kubeadm.go:162] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.24.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0810 15:37:46.168289   97653 kubeadm.go:961] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.24.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0810 15:37:46.168367   97653 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.24.3
I0810 15:37:46.189885   97653 binaries.go:44] Found k8s binaries, skipping transfer
I0810 15:37:46.189963   97653 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0810 15:37:46.211001   97653 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (470 bytes)
I0810 15:37:46.250018   97653 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0810 15:37:46.277312   97653 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2031 bytes)
I0810 15:37:46.307512   97653 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0810 15:37:46.317070   97653 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0810 15:37:46.344271   97653 certs.go:54] Setting up /home/seryum65/.minikube/profiles/minikube for IP: 192.168.49.2
I0810 15:37:46.344541   97653 certs.go:182] skipping minikubeCA CA generation: /home/seryum65/.minikube/ca.key
I0810 15:37:46.344899   97653 certs.go:182] skipping proxyClientCA CA generation: /home/seryum65/.minikube/proxy-client-ca.key
I0810 15:37:46.345356   97653 certs.go:298] skipping minikube-user signed cert generation: /home/seryum65/.minikube/profiles/minikube/client.key
I0810 15:37:46.345605   97653 certs.go:298] skipping minikube signed cert generation: /home/seryum65/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0810 15:37:46.345890   97653 certs.go:298] skipping aggregator signed cert generation: /home/seryum65/.minikube/profiles/minikube/proxy-client.key
I0810 15:37:46.346093   97653 certs.go:388] found cert: /home/seryum65/.minikube/certs/home/seryum65/.minikube/certs/ca-key.pem (1675 bytes)
I0810 15:37:46.346135   97653 certs.go:388] found cert: /home/seryum65/.minikube/certs/home/seryum65/.minikube/certs/ca.pem (1082 bytes)
I0810 15:37:46.346175   97653 certs.go:388] found cert: /home/seryum65/.minikube/certs/home/seryum65/.minikube/certs/cert.pem (1127 bytes)
I0810 15:37:46.346241   97653 certs.go:388] found cert: /home/seryum65/.minikube/certs/home/seryum65/.minikube/certs/key.pem (1675 bytes)
I0810 15:37:46.347280   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0810 15:37:46.383348   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0810 15:37:46.421840   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0810 15:37:46.449006   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0810 15:37:46.472696   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0810 15:37:46.504562   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0810 15:37:46.568440   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0810 15:37:46.634778   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0810 15:37:46.704481   97653 ssh_runner.go:362] scp /home/seryum65/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0810 15:37:46.756997   97653 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0810 15:37:46.794874   97653 ssh_runner.go:195] Run: openssl version
I0810 15:37:46.812762   97653 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0810 15:37:46.834836   97653 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0810 15:37:46.842927   97653 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Aug  9 11:56 /usr/share/ca-certificates/minikubeCA.pem
I0810 15:37:46.843025   97653 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0810 15:37:46.856188   97653 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0810 15:37:46.872883   97653 kubeadm.go:395] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/seryum65:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0810 15:37:46.873072   97653 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0810 15:37:46.946555   97653 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0810 15:37:46.966498   97653 kubeadm.go:410] found existing configuration files, will attempt cluster restart
I0810 15:37:46.966847   97653 kubeadm.go:626] restartCluster start
I0810 15:37:46.966924   97653 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0810 15:37:46.981959   97653 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0810 15:37:46.983109   97653 kubeconfig.go:116] verify returned: extract IP: "minikube" does not appear in /home/seryum65/.kube/config
I0810 15:37:46.983274   97653 kubeconfig.go:127] "minikube" context is missing from /home/seryum65/.kube/config - will repair!
I0810 15:37:46.984098   97653 lock.go:35] WriteFile acquiring /home/seryum65/.kube/config: {Name:mka60ecf8b9f4b218c3541f4cae144b9b557761b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0810 15:37:46.991966   97653 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0810 15:37:47.004797   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:47.004853   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:47.031313   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:47.232293   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:47.232494   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:47.273053   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:47.431707   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:47.431810   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:47.452336   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:47.632227   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:47.632298   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:47.646475   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:47.833555   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:47.833631   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:47.852442   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:48.032262   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:48.032334   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:48.059781   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:48.231564   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:48.231636   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:48.246509   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:48.435666   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:48.435762   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:48.460671   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:48.631423   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:48.631537   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:48.649967   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:48.832363   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:48.832444   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:48.853828   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:49.031727   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:49.031908   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:49.072214   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:49.232073   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:49.232146   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:49.251470   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:49.431824   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:49.432016   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:49.483285   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:49.631997   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:49.632081   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:49.646637   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:49.832106   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:49.832309   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:49.867807   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:50.031776   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:50.031996   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:50.092103   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:50.092149   97653 api_server.go:165] Checking apiserver status ...
I0810 15:37:50.092366   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0810 15:37:50.134502   97653 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0810 15:37:50.134526   97653 kubeadm.go:601] needs reconfigure: apiserver error: timed out waiting for the condition
I0810 15:37:50.134535   97653 kubeadm.go:1092] stopping kube-system containers ...
I0810 15:37:50.134641   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0810 15:37:50.259390   97653 docker.go:443] Stopping containers: [25414d40fadb f554deee7e4c 6ca17037d5ce bff30085f781 31732e536682 7f91bee1ef1d 1e29afe64b24 3f6a0bc1ca96 7c7bb755d222 72ace8f0cc99 f36e68491a12 063b7e939480 c256b515d96e 94981f433635 b39368f8edd4]
I0810 15:37:50.259479   97653 ssh_runner.go:195] Run: docker stop 25414d40fadb f554deee7e4c 6ca17037d5ce bff30085f781 31732e536682 7f91bee1ef1d 1e29afe64b24 3f6a0bc1ca96 7c7bb755d222 72ace8f0cc99 f36e68491a12 063b7e939480 c256b515d96e 94981f433635 b39368f8edd4
I0810 15:37:50.357146   97653 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0810 15:37:50.395784   97653 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0810 15:37:50.408856   97653 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0810 15:37:50.409037   97653 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0810 15:37:50.424635   97653 kubeadm.go:703] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0810 15:37:50.424652   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0810 15:37:50.632945   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0810 15:37:51.849929   97653 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (1.216961591s)
I0810 15:37:51.849942   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0810 15:37:52.342949   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0810 15:37:52.425338   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0810 15:37:52.504573   97653 api_server.go:51] waiting for apiserver process to appear ...
I0810 15:37:52.504655   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:53.023022   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:53.523036   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:54.022955   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:54.523003   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:55.022522   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:55.523783   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:56.023766   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:56.522421   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:37:56.566195   97653 api_server.go:71] duration metric: took 4.061618862s to wait for apiserver process to appear ...
I0810 15:37:56.566210   97653 api_server.go:87] waiting for apiserver healthz status ...
I0810 15:37:56.566220   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:37:56.566541   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0810 15:37:57.067372   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:02.069357   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0810 15:38:02.567301   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:02.582910   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:03.067239   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:03.071366   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:03.567451   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:03.578443   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:04.067403   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:04.072643   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:04.566756   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:04.573377   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:05.067692   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:05.072848   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:05.566994   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:05.581183   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:06.066620   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:06.077202   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:06.566725   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:06.570643   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:07.066946   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:07.071876   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:07.567078   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:07.578429   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:08.066697   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:08.084080   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:08.567095   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:08.570846   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:09.067450   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:09.071486   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:09.566703   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:09.571083   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:10.066886   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:10.087880   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:10.570342   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:10.592799   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:11.067520   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:11.070852   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:11.566938   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:11.594711   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:12.067890   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:12.074036   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:12.567312   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:12.570867   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:13.067960   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:13.074531   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:13.567552   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:13.573745   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:14.067105   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:14.094722   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:14.567379   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:14.572582   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:15.067053   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:15.075535   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:15.567433   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:15.576397   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:16.066839   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:16.073431   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:16.566807   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:16.580689   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:17.066727   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:17.080663   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:17.567512   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:17.573488   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:18.067115   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:18.072180   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:18.567442   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:18.572160   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:19.067147   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:19.078481   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:19.566619   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:19.570787   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:20.067129   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:20.070888   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:20.567266   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:20.570510   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:21.067037   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:21.073076   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:21.566997   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:21.581936   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:22.067488   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:22.072256   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:22.566648   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:22.572355   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:23.066789   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:23.072759   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:23.566983   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:23.585574   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:24.067725   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:24.076674   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:24.567562   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:24.589271   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:25.067020   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:25.072316   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:25.567697   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:25.574570   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:26.067198   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:26.076006   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:26.566973   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:26.575728   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:27.066904   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:27.072129   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:27.567508   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:27.583297   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:28.067731   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:28.099499   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:28.567454   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:28.591897   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:29.067690   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:29.098946   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:29.566879   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:29.571567   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:30.067055   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:30.072751   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:30.567275   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:30.570786   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:31.067143   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:31.087412   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:31.567372   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:31.582207   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:32.066994   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:32.070431   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:32.567587   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:32.578017   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:33.067940   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:33.077659   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:33.567589   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:33.578101   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:34.067210   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:34.070604   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:34.567393   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:34.570653   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:35.067558   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:35.070725   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:35.567254   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:35.570544   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:36.067306   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:36.073177   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:36.566688   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:36.583957   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:37.066645   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:37.072774   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:37.567356   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:37.571234   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:38.066815   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:38.074165   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:38.567402   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:38.573442   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:39.067591   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:39.081087   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:39.567052   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:39.572015   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:40.067406   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:40.076504   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:40.567245   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:40.576264   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:41.067476   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:41.075236   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:41.567707   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:41.592782   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:42.067295   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:42.073589   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:42.566674   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:42.573039   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:43.066793   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:43.074620   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:43.567570   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:43.588264   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:44.067709   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:44.073763   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:44.567705   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:44.585700   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:45.067269   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:45.083165   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:45.567381   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:45.585848   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:46.067777   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:46.088496   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:46.567513   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:46.574323   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:47.067090   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:47.089652   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:47.566654   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:47.572097   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:48.067370   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:48.072831   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:48.567169   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:48.573192   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:49.066923   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:49.073396   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:49.567088   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:49.570354   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:50.067159   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:50.071038   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:50.567659   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:50.575764   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:51.067783   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:51.078523   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:51.567585   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:51.573232   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:52.067173   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:52.072898   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:52.567572   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:52.573047   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:53.067142   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:53.110551   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:53.567372   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:53.572174   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:54.067818   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:54.093578   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:54.567707   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:54.575417   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:55.067509   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:55.074206   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:55.567441   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:55.572925   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:56.067441   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:38:56.073295   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:38:56.567329   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:38:56.697087   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:38:56.697165   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:38:56.742214   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:38:56.742283   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:38:56.793813   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:38:56.793894   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:38:56.833756   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:38:56.833825   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:38:56.892569   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:38:56.892663   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:38:56.928352   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:38:56.928436   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:38:56.966047   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:38:56.966114   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:38:57.013077   97653 logs.go:274] 1 containers: [d2d87260b87b]
I0810 15:38:57.013101   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:38:57.013113   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:38:57.151944   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:38:57.151962   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:38:57.216203   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:38:57.216224   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:38:57.253264   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:38:57.253278   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:38:57.348561   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:38:57.348575   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:38:57.429222   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:38:57.429237   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:38:58.463152   97653 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": (1.03388626s)
I0810 15:38:58.472448   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:38:58.472520   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:38:58.553165   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:38:58.553184   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:38:58.687582   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:38:58.698724   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:38:58.833311   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:38:58.833338   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:38:58.930165   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:38:58.930237   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:38:59.101796   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:38:59.101823   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:38:59.210131   97653 logs.go:123] Gathering logs for kube-controller-manager [d2d87260b87b] ...
I0810 15:38:59.210156   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d2d87260b87b"
I0810 15:38:59.317478   97653 logs.go:123] Gathering logs for container status ...
I0810 15:38:59.317502   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:38:59.553296   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:38:59.553326   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:38:59.799237   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:38:59.799258   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:38:59.882096   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:38:59.882115   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:38:59.959695   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:38:59.959722   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:00.019416   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:00.019444   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:00.132630   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:00.132671   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:02.783326   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:02.818129   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:03.067780   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:03.163685   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:03.163778   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:03.210048   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:03.210117   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:03.264102   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:03.264166   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:03.300680   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:03.300771   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:03.369551   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:03.369620   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:03.408711   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:03.408780   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:03.470301   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:03.470379   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:03.505170   97653 logs.go:274] 1 containers: [d2d87260b87b]
I0810 15:39:03.505214   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:03.505223   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:03.619255   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:03.619268   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:03.729965   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:03.729985   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:03.808411   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:03.808427   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:03.861968   97653 logs.go:123] Gathering logs for kube-controller-manager [d2d87260b87b] ...
I0810 15:39:03.861982   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d2d87260b87b"
I0810 15:39:03.919528   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:03.919540   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:03.950987   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:03.951005   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:04.015902   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:04.015914   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:04.064523   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:04.064539   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:04.183509   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:04.183529   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:04.220419   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:04.220431   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:04.290124   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:04.290137   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:04.325664   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:04.325691   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:04.359073   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:04.359101   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:04.423327   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:04.423340   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:04.483189   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:04.483201   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:04.525913   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:04.525941   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:04.584798   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:04.584836   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:04.620525   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:04.620537   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:04.679691   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:04.679704   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:07.227397   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:07.233661   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:07.566924   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:07.636423   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:07.636495   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:07.738582   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:07.738674   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:07.842783   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:07.842915   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:07.904804   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:07.905023   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:07.944621   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:07.944682   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:08.004747   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:08.004870   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:08.151939   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:08.152033   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:08.269440   97653 logs.go:274] 2 containers: [ebcc50d3fc1c d2d87260b87b]
I0810 15:39:08.269461   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:08.269471   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:08.356253   97653 logs.go:123] Gathering logs for kube-controller-manager [d2d87260b87b] ...
I0810 15:39:08.356269   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d2d87260b87b"
I0810 15:39:08.449387   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:08.449400   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:08.521255   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:08.521274   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:08.639729   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:08.639742   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:08.776424   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:08.776444   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:08.829547   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:08.829563   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:08.854885   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:08.854902   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:08.902192   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:08.902214   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:08.961751   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:08.961766   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:09.059983   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:09.059998   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:09.123660   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:09.123676   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:09.160511   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:09.160522   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:09.232863   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:09.232875   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:09.269109   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:09.269144   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:09.372028   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:09.372042   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:09.430065   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:09.430092   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:09.478153   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:09.478170   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:09.529088   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:09.529105   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:09.599217   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:09.599230   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:09.636501   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:09.636517   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:12.196638   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:12.204765   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:12.567786   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:12.654133   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:12.654246   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:12.720232   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:12.720316   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:12.761881   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:12.761961   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:12.803628   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:12.803699   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:12.849592   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:12.849663   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:12.883229   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:12.883283   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:12.933941   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:12.934011   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:12.968153   97653 logs.go:274] 2 containers: [ebcc50d3fc1c d2d87260b87b]
I0810 15:39:12.968177   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:12.968185   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:13.080273   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:13.080298   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:13.139255   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:13.139267   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:13.174736   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:13.174757   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:13.238075   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:13.238088   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:13.352925   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:13.352939   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:13.397425   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:13.397439   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:13.446144   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:13.446156   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:13.465963   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:13.465978   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:13.563422   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:13.563442   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:13.583730   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:13.583754   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:13.694965   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:13.694978   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:13.791623   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:13.791641   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:13.842095   97653 logs.go:123] Gathering logs for kube-controller-manager [d2d87260b87b] ...
I0810 15:39:13.842119   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d2d87260b87b"
I0810 15:39:13.889847   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:13.889859   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:13.966793   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:13.966806   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:14.004131   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:14.004145   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:14.068672   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:14.068685   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:14.114330   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:14.114345   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:14.158019   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:14.158031   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:14.230961   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:14.230975   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:16.768301   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:16.771939   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:17.067276   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:17.107671   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:17.107737   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:17.165395   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:17.165485   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:17.201945   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:17.202012   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:17.251664   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:17.251767   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:17.297825   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:17.297901   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:17.432184   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:17.432297   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:17.565976   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:17.566112   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:17.671963   97653 logs.go:274] 2 containers: [ebcc50d3fc1c d2d87260b87b]
I0810 15:39:17.672000   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:17.672011   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:17.804118   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:17.804138   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:17.842210   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:17.842228   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:17.977785   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:17.977805   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:18.020237   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:18.020250   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:18.091883   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:18.091896   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:18.134654   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:18.134672   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:18.190798   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:18.190857   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:18.226898   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:18.226914   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:18.280147   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:18.280158   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:18.347014   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:18.347039   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:18.415339   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:18.415351   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:18.530911   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:18.530927   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:18.581031   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:18.581044   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:18.670280   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:18.670293   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:18.717063   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:18.717084   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:18.791314   97653 logs.go:123] Gathering logs for kube-controller-manager [d2d87260b87b] ...
I0810 15:39:18.791333   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d2d87260b87b"
I0810 15:39:18.848079   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:18.848104   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:18.874659   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:18.874676   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:18.917926   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:18.917940   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:19.031572   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:19.031585   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:21.585511   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:21.591203   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:22.067105   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:22.209922   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:22.210046   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:22.259083   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:22.259147   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:22.313356   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:22.313422   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:22.348804   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:22.348887   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:22.397266   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:22.397401   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:22.438505   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:22.438571   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:22.487311   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:22.487418   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:22.546757   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:22.546776   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:22.546798   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:22.604406   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:22.604431   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:22.669016   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:22.669034   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:22.788401   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:22.788439   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:22.830814   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:22.830826   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:22.913514   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:22.913529   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:22.949203   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:22.949215   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:23.021778   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:23.021791   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:23.042022   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:23.042036   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:23.064402   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:23.064422   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:23.181561   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:23.181574   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:23.232591   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:23.232604   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:23.295775   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:23.295797   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:23.335569   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:23.335594   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:23.487410   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:23.487430   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:23.530294   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:23.530312   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:23.573364   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:23.573381   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:23.627082   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:23.627095   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:23.769681   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:23.769701   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:23.839523   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:23.839536   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:26.389333   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:26.407440   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:26.567790   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:26.621840   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:26.621917   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:26.660434   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:26.660514   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:26.699473   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:26.699542   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:26.748584   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:26.748641   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:26.781082   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:26.781144   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:26.832825   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:26.832926   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:26.866599   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:26.866689   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:26.921066   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:26.921089   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:26.921097   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:26.958409   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:26.958421   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:27.027463   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:27.027494   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:27.138742   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:27.138755   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:27.185497   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:27.185509   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:27.256183   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:27.256195   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:27.303580   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:27.303592   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:27.352863   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:27.352881   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:27.435703   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:27.435719   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:27.531716   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:27.531733   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:27.582080   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:27.582091   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:27.637516   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:27.637530   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:27.657893   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:27.657905   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:27.720783   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:27.720802   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:27.807167   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:27.807185   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:27.851330   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:27.851342   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:27.870687   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:27.870700   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:27.940257   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:27.940272   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:28.042950   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:28.042966   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:28.176353   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:28.176369   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:30.780521   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:30.805870   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:31.067467   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:31.146290   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:31.146363   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:31.198669   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:31.198729   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:31.242164   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:31.242254   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:31.282826   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:31.282893   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:31.315014   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:31.315075   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:31.363546   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:31.363645   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:31.398064   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:31.398116   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:31.444209   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:31.444231   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:31.444241   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:31.521866   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:31.521882   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:31.704692   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:31.704706   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:31.796458   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:31.796546   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:31.873212   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:31.873236   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:31.927875   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:31.927916   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:31.981398   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:31.981410   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:32.021296   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:32.021307   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:32.047162   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:32.047179   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:32.089230   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:32.089241   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:32.124392   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:32.124403   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:32.186885   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:32.186897   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:32.343342   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:32.343370   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:32.473772   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:32.473787   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:32.511113   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:32.511126   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:32.607069   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:32.607082   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:32.647516   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:32.647531   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:32.720254   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:32.720267   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:32.746079   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:32.746095   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:32.794968   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:32.794983   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:35.335360   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:35.352597   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:35.567376   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:35.609587   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:35.609665   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:35.643534   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:35.643592   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:35.694454   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:35.694555   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:35.730636   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:35.730706   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:35.766737   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:35.766813   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:35.812358   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:35.812442   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:35.847381   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:35.847450   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:35.903754   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:35.903789   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:35.903797   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:36.009809   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:36.009824   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:36.046051   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:36.046063   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:36.114653   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:36.114665   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:36.156322   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:36.156338   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:36.273553   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:36.273572   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:36.315355   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:36.315372   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:36.419998   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:36.420016   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:36.456519   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:36.456537   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:36.516239   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:36.516263   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:36.553373   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:36.553388   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:36.635133   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:36.635146   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:36.749661   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:36.749673   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:36.822223   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:36.822243   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:36.860424   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:36.860439   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:36.939229   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:36.939268   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:36.986646   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:36.986662   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:37.075270   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:37.075290   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:37.109577   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:37.109596   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:37.193592   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:37.193627   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:39.759940   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:39.763169   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:40.067336   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:40.102859   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:40.102959   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:40.151139   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:40.151216   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:40.185545   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:40.185607   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:40.239470   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:40.239557   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:40.273244   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:40.273344   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:40.314115   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:40.314191   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:40.353733   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:40.353796   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:40.391892   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:40.391943   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:40.391957   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:40.450106   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:40.450120   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:40.565386   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:40.565399   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:40.612583   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:40.612598   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:40.676641   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:40.676654   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:40.746535   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:40.746562   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:40.811640   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:40.811656   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:40.927416   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:40.927428   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:40.969042   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:40.969056   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:41.083521   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:41.083534   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:41.135769   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:41.135791   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:41.156306   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:41.156320   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:41.208191   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:41.208209   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:41.251591   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:41.251701   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:41.271429   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:41.271450   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:41.317094   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:41.317110   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:41.405089   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:41.405109   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:41.450407   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:41.450421   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:41.484952   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:41.484964   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:41.545307   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:41.545342   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:44.118577   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:44.129115   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:44.567294   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:44.606420   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:44.606494   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:44.662692   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:44.662763   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:44.697986   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:44.698054   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:44.759698   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:44.759769   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:44.792851   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:44.792919   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:44.835835   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:44.835928   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:44.877607   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:44.877701   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:44.911169   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:44.911192   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:44.911202   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:44.942608   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:44.942630   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:44.991613   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:44.991627   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:45.046885   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:45.046910   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:45.165324   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:45.165339   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:45.263119   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:45.263153   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:45.301496   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:45.301507   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:45.409625   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:45.409638   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:45.523198   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:45.523221   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:45.571941   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:45.571955   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:45.620408   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:45.620423   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:45.670033   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:45.670044   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:45.706262   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:45.706275   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:45.772798   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:45.772813   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:45.808718   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:45.808731   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:45.864841   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:45.864859   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:46.020492   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:46.020509   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:46.116400   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:46.116414   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:46.144787   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:46.144808   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:46.188463   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:46.188475   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:48.727456   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:48.731542   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:49.067059   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:49.146713   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:49.146978   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:49.230609   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:49.230866   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:49.305555   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:49.305673   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:49.361483   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:49.361553   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:49.440494   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:49.440571   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:49.502297   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:49.502420   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:49.541649   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:49.541715   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:49.590421   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:49.590490   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:49.590506   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:49.613478   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:49.613490   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:49.654440   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:49.654452   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:49.775694   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:49.775711   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:49.837340   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:49.837353   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:49.911359   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:49.911373   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:49.996928   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:49.996948   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:50.035424   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:50.035437   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:50.107455   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:50.107468   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:50.146254   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:50.146267   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:50.200945   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:50.200959   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:50.220849   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:50.220867   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:50.262781   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:50.262802   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:50.368787   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:50.368804   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:50.413869   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:50.413881   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:50.512694   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:50.512710   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:50.552285   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:50.552302   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:50.655650   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:50.655665   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:50.710284   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:50.710296   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:50.761009   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:50.761022   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:53.315997   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:53.319648   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:53.567532   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:53.675004   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:53.675075   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:53.729281   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:53.729373   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:53.770552   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:53.770631   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:53.821233   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:53.821302   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:53.857251   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:53.857330   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:53.912988   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:53.913055   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:53.953544   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:53.953608   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:53.995994   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:53.996014   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:39:53.996025   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:39:54.029390   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:54.029402   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:54.164849   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:54.164863   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:54.229306   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:39:54.229359   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:39:54.276461   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:54.276473   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:54.329674   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:54.329685   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:54.371550   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:54.371562   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:54.520870   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:39:54.520906   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:39:54.622490   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:54.622508   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:54.928782   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:39:54.928847   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:39:55.037204   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:39:55.037217   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:39:55.228846   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:39:55.228864   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:39:55.292159   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:39:55.292180   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:39:55.345455   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:39:55.345476   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:39:55.366247   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:55.366260   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:39:55.439437   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:39:55.439461   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:39:55.478348   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:55.478360   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:55.547566   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:39:55.547577   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:39:55.585198   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:39:55.585209   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:39:55.642162   97653 logs.go:123] Gathering logs for container status ...
I0810 15:39:55.642194   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:39:58.183015   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:39:58.186567   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:39:58.567361   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:39:58.614800   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:39:58.614884   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:39:58.697582   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:39:58.697684   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:39:58.785603   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:39:58.785697   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:39:58.854877   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:39:58.854976   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:39:58.912451   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:39:58.912537   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:39:58.979501   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:39:58.979867   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:39:59.057715   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:39:59.057888   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:39:59.117597   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:39:59.117621   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:39:59.117635   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:39:59.268805   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:39:59.268847   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:39:59.346549   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:39:59.346565   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:39:59.524098   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:39:59.524121   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:39:59.698235   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:39:59.698251   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:39:59.766588   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:39:59.766603   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:39:59.826393   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:39:59.826406   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:39:59.895471   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:39:59.895492   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:00.022337   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:00.022380   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:00.108590   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:00.108607   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:00.152704   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:00.152719   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:00.181671   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:00.181687   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:00.231394   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:00.231426   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:00.332680   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:40:00.332695   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:40:00.452549   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:00.452598   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:00.519106   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:00.519121   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:00.628267   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:00.628280   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:00.689590   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:00.689607   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:00.775801   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:00.775818   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:00.818320   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:00.818333   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:03.339102   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:03.350277   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:03.566750   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:03.737067   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:03.737146   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:03.837052   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:03.837129   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:03.894429   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:03.894505   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:03.970142   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:03.970214   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:04.041781   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:04.041869   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:04.080171   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:04.080292   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:04.127151   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:04.127219   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:04.164153   97653 logs.go:274] 1 containers: [ebcc50d3fc1c]
I0810 15:40:04.164176   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:04.164186   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:04.232158   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:04.232176   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:04.332624   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:04.332639   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:04.367692   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:04.367703   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:04.421122   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:04.421138   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:04.483210   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:04.488266   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:04.522158   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:04.522177   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:04.664231   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:04.664252   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:04.796479   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:04.796498   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:04.864994   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:04.865014   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:04.924038   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:04.924059   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:04.962495   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:04.962516   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:05.021840   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:05.021853   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:05.060682   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:05.060704   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:05.080351   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:05.080363   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:05.134199   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:05.134213   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:05.249504   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:05.249517   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:05.285212   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:05.285230   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:05.335762   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:05.335775   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:05.371884   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:40:05.371895   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:40:07.939487   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:07.942755   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:08.067066   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:08.154455   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:08.154530   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:08.195503   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:08.195566   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:08.247328   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:08.247398   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:08.285410   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:08.285479   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:08.339849   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:08.339916   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:08.374311   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:08.374383   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:08.457664   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:08.457740   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:08.494404   97653 logs.go:274] 2 containers: [055b04b411b4 ebcc50d3fc1c]
I0810 15:40:08.494428   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:40:08.494438   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:40:08.563850   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:08.563863   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:08.640883   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:08.640897   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:08.662011   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:08.662021   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:08.776987   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:08.777000   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:08.834698   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:08.834715   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:08.877160   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:08.877171   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:08.976556   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:08.976569   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:09.011816   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:09.011834   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:09.133564   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:09.133583   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:09.176806   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:09.176818   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:09.234779   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:09.234796   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:09.277785   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:09.277796   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:09.327370   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:09.327387   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:09.354562   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:09.354577   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:09.393356   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:09.393378   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:09.444526   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:09.444539   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:09.525189   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:09.525218   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:09.716813   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:09.716836   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:09.773221   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:09.773232   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:09.853302   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:09.853324   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:12.420743   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:12.427137   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:12.567139   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:12.642402   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:12.642636   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:12.749889   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:12.749954   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:12.829172   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:12.829239   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:12.948162   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:12.948247   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:13.023275   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:13.023349   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:13.094429   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:13.094751   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:13.141664   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:13.141736   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:13.209002   97653 logs.go:274] 2 containers: [055b04b411b4 ebcc50d3fc1c]
I0810 15:40:13.209023   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:13.209034   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:13.266208   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:13.266236   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:13.374742   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:13.374775   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:13.424467   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:13.424480   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:13.452918   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:13.452940   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:13.512404   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:13.512426   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:13.569471   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:13.569500   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:13.634978   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:40:13.634992   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:40:13.702501   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:13.702514   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:13.805749   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:13.805764   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:13.848030   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:13.848049   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:13.906255   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:13.906267   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:13.926485   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:13.926496   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:14.039585   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:14.039603   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:14.098289   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:14.098300   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:14.136046   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:14.136067   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:14.186865   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:14.186885   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:14.254961   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:14.254977   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:14.382722   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:14.382750   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:14.689884   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:14.689901   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:14.794177   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:14.794197   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:17.410367   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:17.429292   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:17.567239   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:17.623344   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:17.623416   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:17.659060   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:17.659129   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:17.715700   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:17.715776   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:17.749834   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:17.749903   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:17.797205   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:17.797269   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:17.838930   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:17.838989   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:17.872129   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:17.872197   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:17.935847   97653 logs.go:274] 2 containers: [055b04b411b4 ebcc50d3fc1c]
I0810 15:40:17.935865   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:17.935872   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:18.053611   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:18.053638   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:18.101579   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:18.101593   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:18.202275   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:18.202291   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:18.241576   97653 logs.go:123] Gathering logs for kube-controller-manager [ebcc50d3fc1c] ...
I0810 15:40:18.241588   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ebcc50d3fc1c"
I0810 15:40:18.296753   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:18.296767   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:18.323208   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:18.323231   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:18.358673   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:18.358685   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:18.418152   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:18.418184   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:18.455809   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:18.455820   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:18.512964   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:18.512994   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:18.561640   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:18.561653   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:18.650085   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:18.650108   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:18.675226   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:18.675245   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:18.744861   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:18.744874   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:18.847539   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:18.847552   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:18.899594   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:18.899623   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:18.959377   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:18.959393   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:19.068629   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:19.068641   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:19.131641   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:19.131656   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:19.196103   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:19.196122   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:21.739503   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:21.744789   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:22.066908   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:22.100665   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:22.100731   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:22.149829   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:22.149939   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:22.184149   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:22.184217   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:22.229527   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:22.229600   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:22.271387   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:22.271449   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:22.308136   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:22.308235   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:22.384647   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:22.384787   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:22.473212   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:22.473232   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:22.473242   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:22.631580   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:22.631595   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:22.730955   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:22.730979   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:22.792059   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:22.792071   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:22.827900   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:22.827911   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:22.865784   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:22.865803   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:22.910101   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:22.910114   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:22.965091   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:22.965103   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:23.000828   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:23.000840   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:23.088859   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:23.088886   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:23.208583   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:23.208613   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:23.372603   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:23.372625   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:23.440583   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:23.440600   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:23.551326   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:23.551347   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:23.626092   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:23.626175   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:23.782134   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:23.782149   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:23.835777   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:23.835793   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:23.887712   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:23.887731   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:23.913986   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:23.913998   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:24.016442   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:24.016453   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:26.631019   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:26.636554   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:27.067183   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:27.106571   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:27.106648   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:27.140526   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:27.140593   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:27.195400   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:27.195467   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:27.230136   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:27.230201   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:27.277365   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:27.277505   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:27.315884   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:27.315958   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:27.349627   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:27.349700   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:27.395390   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:27.395422   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:27.395432   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:27.502386   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:27.502400   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:27.543610   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:27.543621   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:27.643269   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:27.643282   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:27.699336   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:27.699352   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:27.719578   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:27.719624   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:27.756327   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:27.756344   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:27.830322   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:27.830335   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:27.891442   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:27.891460   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:27.929919   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:27.929932   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:28.000492   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:28.000504   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:28.037809   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:28.037823   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:28.095884   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:28.095897   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:28.116756   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:28.116771   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:28.221323   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:28.221336   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:28.256090   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:28.256111   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:28.315311   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:28.315324   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:28.425597   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:28.425616   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:28.503486   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:28.503499   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:28.538411   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:28.538422   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:31.102065   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:31.126400   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:31.567693   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:31.660277   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:31.660356   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:31.695122   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:31.695205   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:31.739192   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:31.739281   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:31.772394   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:31.772459   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:31.823356   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:31.823429   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:31.858843   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:31.858932   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:31.893624   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:31.893737   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:31.941591   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:31.941606   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:31.941613   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:32.025810   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:32.025829   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:32.069974   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:32.069988   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:32.279195   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:32.279209   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:32.347444   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:32.347456   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:32.382784   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:32.382803   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:32.461202   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:32.461225   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:32.509591   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:32.509608   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:32.542706   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:32.542717   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:32.579681   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:32.579695   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:32.637714   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:32.637730   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:32.673944   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:32.673955   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:32.744866   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:32.744886   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:32.818047   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:32.818075   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:32.921589   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:32.921613   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:32.961166   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:32.961178   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:33.067968   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:33.067980   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:33.104163   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:33.104181   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:33.153391   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:33.153406   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:33.212837   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:33.212850   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:35.861916   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:35.883422   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:36.067440   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:36.171538   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:36.171637   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:36.207815   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:36.207878   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:36.260616   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:36.260703   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:36.298964   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:36.299023   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:36.340416   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:36.340489   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:36.383279   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:36.383348   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:36.417126   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:36.417180   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:36.463181   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:36.463204   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:36.463223   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:36.533647   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:36.533676   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:36.583037   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:36.583059   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:36.627798   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:36.627812   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:36.677302   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:36.677320   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:36.722052   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:36.722067   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:36.844283   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:36.844317   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:36.897215   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:36.897228   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:36.952322   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:36.952353   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:36.990181   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:36.990193   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:37.024590   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:37.024604   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:37.086791   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:37.086804   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:37.204264   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:37.204276   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:37.322277   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:37.322294   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:37.378566   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:37.378577   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:37.415395   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:37.415414   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:37.441790   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:37.441807   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:37.471321   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:37.471334   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:37.570681   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:37.570693   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:37.605413   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:37.605426   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:40.185405   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:40.190681   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:40.567338   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:40.621681   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:40.621758   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:40.668738   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:40.668801   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:40.710266   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:40.710346   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:40.747522   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:40.747628   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:40.796629   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:40.796707   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:40.841869   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:40.841931   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:40.890123   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:40.890200   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:40.925302   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:40.925318   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:40.925327   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:41.006817   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:41.006833   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:41.041875   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:41.041887   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:41.117102   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:41.117121   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:41.153810   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:41.153823   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:41.200359   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:41.200383   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:41.241485   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:41.241496   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:41.302889   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:41.302901   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:41.339382   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:41.339394   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:41.372386   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:41.372403   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:41.488797   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:41.488814   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:41.533022   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:41.533034   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:41.642786   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:41.642799   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:41.691678   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:41.691714   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:41.790470   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:41.790486   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:41.811992   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:41.812004   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:41.918975   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:41.918991   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:41.952865   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:41.952877   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:42.011978   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:42.012004   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:42.063180   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:42.063210   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:44.617949   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:44.622715   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:45.066796   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:45.119756   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:45.119827   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:45.156767   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:45.156829   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:45.190808   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:45.190890   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:45.236952   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:45.237018   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:45.270189   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:45.270259   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:45.324909   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:45.324995   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:45.361214   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:45.361287   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:45.405358   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:45.405387   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:45.405399   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:45.475681   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:45.475695   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:45.532058   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:45.532073   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:45.570176   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:45.570198   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:45.593121   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:45.593139   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:45.640718   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:45.640729   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:45.764173   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:45.764186   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:45.827500   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:45.827514   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:45.864860   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:45.864871   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:45.885433   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:45.885451   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:45.990435   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:45.990451   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:46.101561   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:46.101577   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:46.209021   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:46.209037   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:46.251346   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:46.251359   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:46.286498   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:46.286509   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:46.354108   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:46.354128   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:46.391445   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:46.391459   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:46.448568   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:46.448582   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:46.489234   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:46.489248   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:46.540718   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:46.540729   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:49.107175   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:49.111350   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:49.567718   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:49.608675   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:49.608764   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:49.678614   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:49.678711   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:49.720480   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:49.720569   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:49.771078   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:49.771150   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:49.806258   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:49.806323   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:49.873769   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:49.873849   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:49.958437   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:49.958557   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:50.082481   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:50.082506   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:50.082518   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:50.219338   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:50.219355   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:50.374157   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:50.374178   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:50.471383   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:50.471404   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:50.506858   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:50.506871   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:50.578603   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:50.578616   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:50.599328   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:50.599341   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:50.677681   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:50.677693   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:50.797696   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:50.797710   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:50.834552   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:50.834573   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:50.954514   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:50.954529   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:50.996323   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:50.996335   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:51.032185   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:51.032204   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:51.102216   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:51.102228   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:51.145796   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:51.145811   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:51.174688   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:51.174705   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:51.262987   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:51.263055   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:51.324830   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:51.324860   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:51.401032   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:51.401047   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:51.500242   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:51.500343   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:54.100077   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:54.122092   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:54.567159   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:54.611243   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:54.611294   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:54.650071   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:54.650138   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:54.706303   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:54.706378   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:54.750666   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:54.750826   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:54.840400   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:54.840521   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:54.939053   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:54.939142   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:55.016494   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:55.016809   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:55.090240   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:55.090290   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:40:55.090301   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:40:55.189701   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:40:55.189719   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:40:55.264809   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:55.264821   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:55.336841   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:40:55.336853   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:40:55.444438   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:40:55.444455   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:40:55.495522   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:40:55.504871   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:40:55.645783   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:40:55.645815   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:40:55.735109   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:40:55.735143   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:40:55.815336   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:40:55.815364   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:40:55.903215   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:40:55.903229   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:40:55.936768   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:40:55.936809   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:40:55.958753   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:55.958773   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:40:56.079854   97653 logs.go:123] Gathering logs for container status ...
I0810 15:40:56.079873   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:40:56.169808   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:40:56.169822   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:40:56.253731   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:40:56.253763   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:40:56.347766   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:40:56.347779   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:40:56.396619   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:40:56.396631   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:40:56.443761   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:40:56.443773   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:40:56.506780   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:40:56.506801   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:40:56.634249   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:40:56.634268   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:40:59.244149   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:40:59.250607   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:40:59.567190   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:40:59.603094   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:40:59.603163   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:40:59.662478   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:40:59.662554   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:40:59.701443   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:40:59.701518   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:40:59.754997   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:40:59.755067   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:40:59.790964   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:40:59.791036   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:40:59.845040   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:40:59.845123   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:40:59.879235   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:40:59.879306   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:40:59.926310   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:40:59.926337   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:40:59.926347   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:40:59.985255   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:40:59.985270   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:00.101357   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:00.101370   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:00.202130   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:00.202144   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:00.277304   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:00.277318   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:00.296795   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:00.296808   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:00.375839   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:00.375859   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:00.439351   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:00.439404   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:00.480610   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:00.480624   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:00.525922   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:00.525937   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:00.581764   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:00.581778   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:00.635502   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:00.635517   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:00.681120   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:00.681133   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:00.724894   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:00.724908   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:00.761289   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:00.761397   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:00.833742   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:00.833760   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:01.020402   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:01.020417   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:01.094264   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:01.094276   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:01.150488   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:01.150500   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:01.260856   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:01.260869   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:03.797296   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:03.811569   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:04.067076   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:04.120534   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:04.120601   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:04.180445   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:04.180520   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:04.225256   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:04.225344   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:04.281392   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:04.281462   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:04.315941   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:04.315994   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:04.363337   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:04.363415   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:04.407398   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:04.407476   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:04.454918   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:04.454945   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:04.454953   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:04.490740   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:04.490766   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:04.609905   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:04.609918   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:04.725136   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:04.725149   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:04.780079   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:04.780093   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:04.849621   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:04.849648   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:04.898479   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:04.898496   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:05.002553   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:05.002567   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:05.065028   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:05.065046   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:05.111963   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:05.111978   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:05.163822   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:05.163833   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:05.242255   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:05.242289   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:05.287199   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:05.287215   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:05.338089   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:05.338103   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:05.399051   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:05.399066   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:05.436858   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:05.436871   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:05.559391   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:05.559414   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:05.610524   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:05.610536   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:05.656215   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:05.656230   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:05.717403   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:05.717416   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:08.265550   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:08.278381   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:08.567231   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:08.649028   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:08.649107   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:08.738562   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:08.738635   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:08.823039   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:08.823138   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:08.916415   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:08.916492   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:08.957284   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:08.957390   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:09.011447   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:09.011543   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:09.076978   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:09.077333   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:09.141485   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:09.141508   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:09.141525   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:09.215435   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:09.215461   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:09.292058   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:09.292076   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:09.324613   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:09.324660   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:09.381643   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:09.381660   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:09.541339   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:09.541362   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:09.711838   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:09.711877   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:09.861800   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:09.861822   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:09.982130   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:09.982157   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:10.035300   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:10.035317   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:10.144739   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:10.144752   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:10.180191   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:10.180203   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:10.255995   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:10.256008   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:10.311429   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:10.311441   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:10.401680   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:10.401701   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:10.516225   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:10.516305   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:10.575951   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:10.575991   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:10.610996   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:10.611070   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:10.731999   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:10.732016   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:10.865307   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:10.865321   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:13.482576   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:13.486912   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:13.567463   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:13.681918   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:13.682010   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:13.778589   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:13.778680   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:13.859303   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:13.859378   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:13.906773   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:13.906851   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:13.952711   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:13.952830   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:13.995294   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:13.995360   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:14.050807   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:14.050897   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:14.086038   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:14.086057   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:14.086067   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:14.109109   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:14.109121   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:14.168825   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:14.168850   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:14.211568   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:14.211581   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:14.294009   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:14.294021   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:14.364036   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:14.364051   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:14.385156   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:14.385168   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:14.444977   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:14.445007   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:14.572093   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:14.572107   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:14.605635   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:14.605651   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:14.737032   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:14.737048   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:14.783081   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:14.783093   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:14.821029   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:14.821049   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:14.917604   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:14.917617   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:15.045304   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:15.045330   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:15.083884   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:15.083897   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:15.119999   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:15.120032   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:15.181591   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:15.181604   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:15.257125   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:15.257140   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:15.292745   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:15.292759   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:17.852148   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:17.857710   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:18.067149   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:18.127684   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:18.127772   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:18.207963   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:18.208075   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:18.242243   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:18.242305   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:18.296780   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:18.296868   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:18.330172   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:18.330257   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:18.378784   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:18.378877   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:18.417894   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:18.417957   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:18.456114   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:18.456134   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:18.456143   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:18.509557   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:18.509569   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:18.566225   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:18.566242   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:18.612677   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:18.612699   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:18.723253   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:18.723266   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:18.803284   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:18.803317   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:18.968433   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:18.968450   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:19.034247   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:19.034292   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:19.116570   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:19.116589   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:19.145354   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:19.145412   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:19.291779   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:19.291799   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:19.403278   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:19.403295   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:19.438766   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:19.438778   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:19.551537   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:19.551561   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:19.607779   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:19.607791   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:19.646959   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:19.646976   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:19.676482   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:19.676498   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:19.721546   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:19.721559   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:19.802521   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:19.802569   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:19.877928   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:19.877946   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:22.453402   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:22.456996   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:22.568055   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:22.688965   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:22.689067   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:22.752439   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:22.752522   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:22.796793   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:22.796877   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:22.840486   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:22.840547   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:22.875438   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:22.875508   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:22.931386   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:22.931453   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:22.973886   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:22.973993   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:23.039464   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:23.039482   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:23.039499   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:23.069521   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:23.069567   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:23.099477   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:23.099512   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:23.179064   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:23.179086   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:23.319734   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:23.319762   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:23.465008   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:23.465029   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:23.609137   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:23.609155   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:23.656392   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:23.656404   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:23.761008   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:23.761021   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:23.803369   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:23.803385   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:23.856438   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:23.856455   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:23.992345   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:23.992358   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:24.045546   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:24.045558   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:24.083155   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:24.083167   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:24.135677   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:24.135693   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:24.236878   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:24.236900   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:24.393790   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:24.394447   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:24.519912   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:24.519940   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:24.592439   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:24.592454   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:24.647074   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:24.647102   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:27.206342   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:27.228182   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:27.567953   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:27.732150   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:27.732231   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:27.811837   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:27.811920   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:27.915138   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:27.915211   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:28.003645   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:28.003726   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:28.082492   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:28.082603   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:28.178143   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:28.178344   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:28.287952   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:28.288051   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:28.384038   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:28.384063   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:28.384075   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:28.498726   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:28.498742   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:28.578357   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:28.578373   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:28.632750   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:28.632776   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:28.708091   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:28.708108   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:28.823721   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:28.823734   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:28.879725   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:28.879741   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:28.922874   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:28.922888   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:28.971352   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:28.971364   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:29.015299   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:29.015348   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:29.092775   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:29.092807   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:29.119040   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:29.119055   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:29.274404   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:29.274417   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:29.310204   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:29.310217   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:29.388611   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:29.388624   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:29.456199   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:29.456243   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:29.550578   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:29.550605   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:29.637175   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:29.637194   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:29.717784   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:29.717801   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:29.904104   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:29.904119   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:32.428193   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:32.432098   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:32.566973   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:32.634264   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:32.634329   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:32.702409   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:32.702502   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:32.747542   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:32.747649   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:32.798287   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:32.798350   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:32.833669   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:32.833720   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:32.887529   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:32.887636   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:32.928541   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:32.928624   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:32.975508   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:32.975527   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:32.975536   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:33.092074   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:33.092104   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:33.131698   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:33.131711   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:33.155477   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:33.155528   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:33.232265   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:33.232285   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:33.287690   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:33.287718   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:33.330759   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:33.330770   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:33.391846   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:33.391864   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:33.496792   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:33.496830   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:33.543095   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:33.543126   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:33.655661   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:33.655675   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:33.711017   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:33.711031   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:33.750644   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:33.750655   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:33.826694   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:33.826708   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:33.861314   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:33.861326   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:33.917937   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:33.917962   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:33.995218   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:33.995236   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:34.018404   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:34.018416   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:34.053676   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:34.053687   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:34.167015   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:34.167032   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:36.725945   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:36.744994   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:37.066967   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:37.126223   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:37.126292   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:37.169687   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:37.169739   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:37.227346   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:37.227440   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:37.283261   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:37.283330   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:37.341148   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:37.341230   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:37.381984   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:37.382070   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:37.431882   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:37.431960   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:37.469360   97653 logs.go:274] 1 containers: [055b04b411b4]
I0810 15:41:37.469383   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:37.469391   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:37.489915   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:37.489934   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:37.548988   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:37.549001   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:37.585451   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:37.585463   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:37.614561   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:37.614578   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:37.687671   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:37.687684   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:37.798652   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:37.798677   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:37.842398   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:37.842412   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:37.956666   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:37.956679   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:37.998341   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:37.998360   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:38.052953   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:38.052980   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:38.167604   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:38.167625   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:38.272814   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:38.272827   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:38.337367   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:38.337382   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:38.373046   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:38.373058   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:38.431921   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:38.431949   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:38.478200   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:38.478211   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:38.554124   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:38.554137   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:38.598955   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:38.598978   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:38.658355   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:38.658368   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:41.222609   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:41.229494   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:41.567573   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:41.666248   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:41.666319   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:41.730286   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:41.730406   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:41.830272   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:41.830354   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:41.883244   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:41.883375   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:41.947144   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:41.947256   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:42.107654   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:42.107738   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:42.208526   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:42.208615   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:42.286923   97653 logs.go:274] 2 containers: [b71f80a30798 055b04b411b4]
I0810 15:41:42.286949   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:42.286957   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:42.411769   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:42.411782   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:42.507689   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:42.507708   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:42.580768   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:42.580838   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:42.676736   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:42.676762   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:42.730739   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:42.730754   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:42.810750   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:42.810764   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:42.844083   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:42.844101   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:42.920383   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:42.920399   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:43.086881   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:43.086922   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:43.131734   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:43.131754   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:43.202778   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:43.202801   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:43.406581   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:43.406632   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:43.541907   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:43.541927   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:43.618186   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:43.618254   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:43.703533   97653 logs.go:123] Gathering logs for kube-controller-manager [b71f80a30798] ...
I0810 15:41:43.703546   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b71f80a30798"
I0810 15:41:43.786976   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:43.787001   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:43.843411   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:43.843425   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:43.942167   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:43.942238   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:44.026887   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:44.026907   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:44.141812   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:44.141824   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:46.675230   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:46.682308   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:47.067648   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:47.168690   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:47.168761   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:47.276045   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:47.276135   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:47.399318   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:47.399412   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:47.512198   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:47.512293   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:47.591318   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:47.591421   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:47.665939   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:47.666021   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:47.759936   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:47.760010   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:47.848830   97653 logs.go:274] 2 containers: [b71f80a30798 055b04b411b4]
I0810 15:41:47.848864   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:47.848875   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:47.958371   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:47.958387   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:48.035523   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:48.035550   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:48.277618   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:48.277636   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:48.372724   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:48.372773   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:48.466027   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:48.466040   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:48.527584   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:48.527727   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:48.568141   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:48.568161   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:48.620566   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:48.620593   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:48.752573   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:48.752595   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:48.959971   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:48.959988   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:49.055955   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:49.055973   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:49.290411   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:49.290456   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:49.517623   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:49.517646   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:49.618568   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:49.618588   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:49.725446   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:49.725466   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:49.786467   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:49.786486   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:49.889894   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:49.890040   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:49.986659   97653 logs.go:123] Gathering logs for kube-controller-manager [b71f80a30798] ...
I0810 15:41:49.986671   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b71f80a30798"
I0810 15:41:50.073227   97653 logs.go:123] Gathering logs for kube-controller-manager [055b04b411b4] ...
I0810 15:41:50.073253   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 055b04b411b4"
I0810 15:41:50.231285   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:50.231313   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:52.776038   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:52.781311   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:53.066994   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:41:53.109625   97653 logs.go:274] 2 containers: [848d7f966f18 3f6a0bc1ca96]
I0810 15:41:53.109690   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:41:53.161026   97653 logs.go:274] 2 containers: [bcbd1fa7ef0d 72ace8f0cc99]
I0810 15:41:53.161098   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:41:53.197072   97653 logs.go:274] 2 containers: [5585719eb654 f554deee7e4c]
I0810 15:41:53.197134   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:41:53.241553   97653 logs.go:274] 2 containers: [669ab3c7955a 7c7bb755d222]
I0810 15:41:53.241652   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:41:53.287273   97653 logs.go:274] 2 containers: [1299fd43701d bff30085f781]
I0810 15:41:53.287332   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:41:53.326979   97653 logs.go:274] 2 containers: [2afc98d741d0 4820f29e533f]
I0810 15:41:53.327065   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:41:53.375295   97653 logs.go:274] 2 containers: [b53428705176 f3eed7bcd074]
I0810 15:41:53.375371   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:41:53.412909   97653 logs.go:274] 1 containers: [b71f80a30798]
I0810 15:41:53.412947   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:41:53.412957   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:41:53.438520   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:41:53.438537   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:41:53.550284   97653 logs.go:123] Gathering logs for etcd [72ace8f0cc99] ...
I0810 15:41:53.550302   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 72ace8f0cc99"
I0810 15:41:53.669738   97653 logs.go:123] Gathering logs for kube-proxy [1299fd43701d] ...
I0810 15:41:53.669751   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1299fd43701d"
I0810 15:41:53.706827   97653 logs.go:123] Gathering logs for kube-proxy [bff30085f781] ...
I0810 15:41:53.706842   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bff30085f781"
I0810 15:41:53.756119   97653 logs.go:123] Gathering logs for container status ...
I0810 15:41:53.756131   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:41:53.802246   97653 logs.go:123] Gathering logs for kube-apiserver [3f6a0bc1ca96] ...
I0810 15:41:53.802264   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3f6a0bc1ca96"
I0810 15:41:53.919579   97653 logs.go:123] Gathering logs for etcd [bcbd1fa7ef0d] ...
I0810 15:41:53.919602   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bcbd1fa7ef0d"
I0810 15:41:53.978983   97653 logs.go:123] Gathering logs for coredns [5585719eb654] ...
I0810 15:41:53.979000   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5585719eb654"
I0810 15:41:54.020304   97653 logs.go:123] Gathering logs for kube-scheduler [7c7bb755d222] ...
I0810 15:41:54.020327   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7c7bb755d222"
I0810 15:41:54.087395   97653 logs.go:123] Gathering logs for kube-controller-manager [b71f80a30798] ...
I0810 15:41:54.087409   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b71f80a30798"
I0810 15:41:54.139415   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:41:54.139436   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:41:54.169479   97653 logs.go:123] Gathering logs for coredns [f554deee7e4c] ...
I0810 15:41:54.169504   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f554deee7e4c"
I0810 15:41:54.227467   97653 logs.go:123] Gathering logs for kubernetes-dashboard [2afc98d741d0] ...
I0810 15:41:54.227481   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2afc98d741d0"
I0810 15:41:54.318024   97653 logs.go:123] Gathering logs for kubernetes-dashboard [4820f29e533f] ...
I0810 15:41:54.318043   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4820f29e533f"
I0810 15:41:54.434912   97653 logs.go:123] Gathering logs for storage-provisioner [b53428705176] ...
I0810 15:41:54.434963   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b53428705176"
I0810 15:41:54.511486   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:41:54.511508   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:41:54.693373   97653 logs.go:123] Gathering logs for kube-apiserver [848d7f966f18] ...
I0810 15:41:54.693387   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 848d7f966f18"
I0810 15:41:54.741945   97653 logs.go:123] Gathering logs for kube-scheduler [669ab3c7955a] ...
I0810 15:41:54.741957   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 669ab3c7955a"
I0810 15:41:54.861495   97653 logs.go:123] Gathering logs for storage-provisioner [f3eed7bcd074] ...
I0810 15:41:54.861508   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f3eed7bcd074"
I0810 15:41:57.440161   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:41:57.443689   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:41:57.443744   97653 kubeadm.go:630] restartCluster took 4m10.476890212s
W0810 15:41:57.443846   97653 out.go:239] ü§¶  Unable to restart cluster, will reset it: apiserver health: apiserver healthz never reported healthy: cluster wait timed out during healthz check
I0810 15:41:57.443915   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force"
I0810 15:42:08.871910   97653 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force": (11.427977173s)
I0810 15:42:08.871986   97653 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0810 15:42:08.883742   97653 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0810 15:42:08.892335   97653 kubeadm.go:221] ignoring SystemVerification for kubeadm because of docker driver
I0810 15:42:08.892388   97653 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0810 15:42:08.901311   97653 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0810 15:42:08.901332   97653 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0810 15:42:09.182427   97653 out.go:204]     ‚ñ™ Generating certificates and keys ...
I0810 15:42:09.895644   97653 out.go:204]     ‚ñ™ Booting up control plane ...
I0810 15:42:24.501199   97653 out.go:204]     ‚ñ™ Configuring RBAC rules ...
I0810 15:42:25.059396   97653 cni.go:95] Creating CNI manager for ""
I0810 15:42:25.059420   97653 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0810 15:42:25.059446   97653 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0810 15:42:25.059647   97653 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0810 15:42:25.060129   97653 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl label nodes minikube.k8s.io/version=v1.26.1 minikube.k8s.io/commit=62e108c3dfdec8029a890ad6d8ef96b6461426dc minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2022_08_10T15_42_25_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0810 15:42:25.424913   97653 ops.go:34] apiserver oom_adj: -16
I0810 15:42:25.424944   97653 kubeadm.go:1045] duration metric: took 365.394895ms to wait for elevateKubeSystemPrivileges.
I0810 15:42:25.424960   97653 kubeadm.go:397] StartCluster complete in 4m38.552086322s
I0810 15:42:25.424976   97653 settings.go:142] acquiring lock: {Name:mk85c999cc28613e6dc88bb8a3b89ffa691bca71 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0810 15:42:25.425081   97653 settings.go:150] Updating kubeconfig:  /home/seryum65/.kube/config
I0810 15:42:25.425888   97653 lock.go:35] WriteFile acquiring /home/seryum65/.kube/config: {Name:mka60ecf8b9f4b218c3541f4cae144b9b557761b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
W0810 15:42:25.456266   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:25.972969   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:26.460449   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:26.989308   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:27.473954   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:27.962178   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:28.477795   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:28.985536   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:29.461894   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:29.962753   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:30.461174   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:30.963043   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:31.461517   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:31.960895   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:32.486898   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:32.963005   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:33.462463   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:33.965069   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:34.465106   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:34.967083   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:35.475020   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:35.960880   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:36.461090   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:36.960004   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:37.466802   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:37.961207   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:38.460833   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:38.960757   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:39.479501   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:39.965071   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:40.459917   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:40.965105   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:41.465334   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:41.964551   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:42.462637   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:42.962247   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:43.460846   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:43.961465   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:44.466226   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:44.960934   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:45.477070   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:45.960887   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:46.461475   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:46.962295   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:47.483737   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:47.979519   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:48.473376   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:48.961694   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:49.465971   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:49.967740   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:50.462242   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:50.972800   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:51.464684   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:51.971775   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:52.462728   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:52.962039   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:53.460896   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:53.979090   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:54.461125   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:54.965803   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:55.461975   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:55.963002   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:56.494021   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:56.968173   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:57.459581   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:57.961663   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:58.460305   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:58.964474   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:59.463796   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:42:59.962502   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:00.488731   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:00.981935   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:01.463271   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:01.964968   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:02.471326   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:02.963640   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:03.462269   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:03.960702   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:04.461551   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:04.979779   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:05.467168   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:05.961728   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:06.476479   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:06.964250   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:07.462851   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:07.964607   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:08.462131   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:08.962558   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:09.464099   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:09.972119   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:10.469936   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:10.959904   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:11.472987   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:11.971151   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:12.470098   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:12.981920   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:13.461790   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:13.962574   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:14.484116   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:14.971439   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:15.474612   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:15.972440   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:16.468908   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:16.971165   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:17.468445   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:17.970098   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:18.470074   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:18.971359   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:19.469002   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:19.971253   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:20.460128   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:20.961936   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:21.472828   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:21.968523   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:22.467825   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:22.960221   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:23.467742   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:23.968937   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:24.468414   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:24.962020   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:25.459989   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:25.965968   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:26.461979   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:26.970054   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:27.470432   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:27.969299   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:28.470927   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:28.963534   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:29.469836   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:29.970192   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:30.469399   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:30.968620   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:31.472284   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:31.978704   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:32.472148   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:32.970249   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:33.470849   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:33.968873   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:34.474983   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:34.970780   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:35.462888   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:35.982623   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:36.462994   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:36.962251   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:37.463894   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:37.964990   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:38.460430   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:38.962074   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:39.466522   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:39.961922   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:40.473874   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:40.960789   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:41.459871   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:41.974133   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:42.473530   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:42.976506   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:43.460449   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:43.973603   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:44.469653   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:44.971009   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:45.474672   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:45.970675   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:46.472904   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:46.959983   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:47.472341   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:47.972836   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:48.471926   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:48.973782   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:49.469476   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:49.969994   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:50.470244   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:50.972629   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:51.461680   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:51.970596   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:52.469463   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:52.969266   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:53.470164   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:53.968739   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:54.469801   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:54.960999   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:55.469588   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:55.971934   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:56.472202   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:56.969860   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:57.471039   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:57.972112   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:58.475402   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:58.971304   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:59.471474   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:43:59.974424   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:00.473105   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:00.973864   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:01.472751   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:01.972797   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:02.472470   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:02.972710   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:03.472516   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:03.969391   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:04.474255   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:04.963212   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:05.473206   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:05.965968   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:06.470201   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:06.959712   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:07.470441   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:07.966535   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:08.474587   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:08.973693   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:09.465723   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:09.974178   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:10.472038   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:10.964919   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:11.460486   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:11.977089   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:12.479827   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:12.972739   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:13.462779   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:13.973269   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:14.472794   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:14.971575   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:15.461571   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:15.969638   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:16.473315   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:16.960777   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:17.476015   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:17.975178   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:18.460545   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:18.974238   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:19.473478   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:19.972970   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:20.478089   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:20.987035   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:21.463680   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:21.960202   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:22.474740   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:22.971949   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:23.473788   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:23.979327   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:24.459690   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:24.975212   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:25.474193   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 15:44:25.489468   97653 kapi.go:226] failed getting deployment scale, will retry: Get "https://192.168.49.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:25.491205   97653 kapi.go:241] timed out trying to rescale deployment "coredns" in namespace "kube-system" and context "minikube" to 1: timed out waiting for the condition
E0810 15:44:25.491233   97653 start.go:267] Unable to scale down deployment "coredns" in namespace "kube-system" to 1 replica: timed out waiting for the condition
I0810 15:44:25.491382   97653 start.go:211] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0810 15:44:25.501003   97653 out.go:177] üîé  Verifying Kubernetes components...
I0810 15:44:25.491765   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0810 15:44:25.491485   97653 addons.go:412] enableAddons start: toEnable=map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false], additional=[]
I0810 15:44:25.492629   97653 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0810 15:44:25.513576   97653 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0810 15:44:25.514961   97653 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I0810 15:44:25.515008   97653 addons.go:65] Setting dashboard=true in profile "minikube"
I0810 15:44:25.515025   97653 addons.go:65] Setting default-storageclass=true in profile "minikube"
I0810 15:44:25.523799   97653 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0810 15:44:25.525175   97653 addons.go:153] Setting addon dashboard=true in "minikube"
W0810 15:44:25.525200   97653 addons.go:162] addon dashboard should already be in state true
I0810 15:44:25.525275   97653 host.go:66] Checking if "minikube" exists ...
I0810 15:44:25.525793   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0810 15:44:25.526001   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0810 15:44:25.526171   97653 addons.go:153] Setting addon storage-provisioner=true in "minikube"
W0810 15:44:25.526185   97653 addons.go:162] addon storage-provisioner should already be in state true
I0810 15:44:25.526239   97653 host.go:66] Checking if "minikube" exists ...
I0810 15:44:25.527241   97653 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0810 15:44:25.637671   97653 out.go:177]     ‚ñ™ Using image kubernetesui/metrics-scraper:v1.0.8
W0810 15:44:25.643042   97653 out.go:239] ‚ùó  Enabling 'default-storageclass' returned an error: running callbacks: [Error making standard the default storage class: Error listing StorageClasses: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2]
I0810 15:44:25.653566   97653 out.go:177]     ‚ñ™ Using image kubernetesui/dashboard:v2.6.0
I0810 15:44:25.659317   97653 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0810 15:44:25.675884   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-ns.yaml
I0810 15:44:25.675894   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-ns.yaml (759 bytes)
I0810 15:44:25.684043   97653 addons.go:345] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0810 15:44:25.661918   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.49.1 host.minikube.internal\n           fallthrough\n        }' | sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0810 15:44:25.684052   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0810 15:44:25.684094   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:44:25.661934   97653 api_server.go:51] waiting for apiserver process to appear ...
I0810 15:44:25.675980   97653 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0810 15:44:25.684166   97653 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0810 15:44:25.750753   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:44:25.771384   97653 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/seryum65/.minikube/machines/minikube/id_rsa Username:docker}
I0810 15:44:25.895626   97653 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0810 15:44:25.914053   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-clusterrole.yaml
I0810 15:44:25.914062   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrole.yaml (1001 bytes)
I0810 15:44:25.933264   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml
I0810 15:44:25.933274   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml (1018 bytes)
I0810 15:44:25.970856   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-configmap.yaml
I0810 15:44:25.970869   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-configmap.yaml (837 bytes)
I0810 15:44:25.992644   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-dp.yaml
I0810 15:44:25.992653   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-dp.yaml (4278 bytes)
I0810 15:44:26.007735   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-role.yaml
I0810 15:44:26.007748   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-role.yaml (1724 bytes)
I0810 15:44:26.023202   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-rolebinding.yaml
I0810 15:44:26.023229   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-rolebinding.yaml (1046 bytes)
I0810 15:44:26.062944   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-sa.yaml
I0810 15:44:26.062968   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-sa.yaml (837 bytes)
I0810 15:44:26.079488   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-secret.yaml
I0810 15:44:26.079504   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-secret.yaml (1389 bytes)
I0810 15:44:26.094689   97653 addons.go:345] installing /etc/kubernetes/addons/dashboard-svc.yaml
I0810 15:44:26.094708   97653 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-svc.yaml (1294 bytes)
I0810 15:44:26.115153   97653 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0810 15:44:26.987840   97653 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (1.303654201s)
I0810 15:44:26.987855   97653 api_server.go:71] duration metric: took 1.496427053s to wait for apiserver process to appear ...
I0810 15:44:26.987868   97653 api_server.go:87] waiting for apiserver healthz status ...
I0810 15:44:26.987878   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:26.988202   97653 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.49.1 host.minikube.internal\n           fallthrough\n        }' | sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -": (1.304134912s)
I0810 15:44:26.988217   97653 start.go:809] {"host.minikube.internal": 192.168.49.1} host record injected into CoreDNS
I0810 15:44:26.993071   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:27.197393   97653 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (1.301690285s)
I0810 15:44:27.494233   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:27.515473   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:27.540786   97653 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: (1.425534973s)
I0810 15:44:27.552393   97653 out.go:177] üåü  Enabled addons: storage-provisioner, dashboard
I0810 15:44:27.565479   97653 addons.go:414] enableAddons completed in 2.073930861s
I0810 15:44:27.994243   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:28.012259   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:28.493480   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:28.518436   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:28.993205   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:29.001470   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:29.494022   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:29.499852   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:29.993393   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:30.001091   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:30.493203   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:30.522892   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:30.993283   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:30.996772   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:31.493549   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:31.510807   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:31.993167   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:31.996308   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:32.493838   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:32.509297   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:32.994070   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:33.008074   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:33.493595   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:33.511110   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:33.993521   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:34.010140   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:34.493622   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:34.506816   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:34.993338   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:35.007251   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:35.493858   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:35.511159   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:35.993499   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:35.998676   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:36.494085   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:36.504323   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:36.993950   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:36.998906   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:37.493200   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:37.496385   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:37.994121   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:38.004185   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:38.493670   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:38.504144   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:38.993810   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:39.005047   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:39.493383   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:39.505999   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:39.993472   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:40.006317   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:40.493313   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:40.512928   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:40.993394   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:41.004101   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:41.493323   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:41.506006   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:41.993535   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:42.007009   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:42.493366   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:42.509423   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:42.994052   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:43.008592   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:43.494073   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:43.509765   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:43.993405   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:44.009135   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:44.493377   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:44.507157   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:44.993317   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:44.997206   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:45.494323   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:45.520928   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:45.993263   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:46.000333   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:46.494235   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:46.517866   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:46.994027   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:47.010620   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:47.494356   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:47.509933   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:47.993285   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:47.997750   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:48.493328   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:48.504426   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:48.993284   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:49.011519   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:49.494203   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:49.509851   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:49.993221   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:49.997551   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:50.494296   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:50.518117   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:50.993609   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:50.996779   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:51.493504   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:51.507163   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:51.993591   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:51.997904   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:52.493369   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:52.498539   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:52.994136   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:53.001966   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:53.493356   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:53.497524   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:53.994139   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:53.998431   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:54.494168   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:54.515008   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:54.993470   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:55.013091   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:55.493675   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:55.524334   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:55.993372   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:56.012095   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:56.494415   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:56.512635   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:56.994215   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:56.997424   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:57.493840   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:57.499374   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:57.993853   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:57.998115   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:58.494066   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:58.511286   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:58.993660   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:59.010576   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:59.494223   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:44:59.512115   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:44:59.993533   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:00.011562   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:00.493952   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:00.514639   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:00.993382   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:01.005422   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:01.494212   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:01.506590   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:01.994247   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:02.006783   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:02.493317   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:02.498115   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:02.994039   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:03.006675   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:03.493296   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:03.504981   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:03.993298   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:04.000095   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:04.493220   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:04.498316   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:04.993870   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:04.998873   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:05.493515   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:05.508381   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:05.994014   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:05.998577   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:06.493393   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:06.512714   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:06.993603   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:06.998094   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:07.493595   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:07.497418   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:07.994219   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:08.008210   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:08.493435   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:08.508191   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:08.993601   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:08.998500   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:09.493332   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:09.515378   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:09.993377   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:10.001056   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:10.494186   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:10.515985   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:10.993393   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:11.007484   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:11.494253   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:11.511134   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:11.993641   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:12.010779   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:12.494334   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:12.510620   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:12.994402   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:13.011924   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:13.493602   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:13.508849   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:13.993969   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:14.008916   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:14.493633   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:14.506781   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:14.993502   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:15.009322   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:15.493317   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:15.521243   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:15.993541   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:16.016381   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:16.493417   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:16.507191   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:16.994149   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:17.010445   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:17.493906   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:17.499007   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:17.993490   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:18.010827   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:18.494101   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:18.507714   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:18.993456   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:19.018409   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:19.493323   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:19.512682   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:19.994488   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:20.010976   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:20.493495   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:20.516412   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:20.994286   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:21.011837   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:21.494218   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:21.502742   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:21.994114   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:22.007300   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:22.494398   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:22.513460   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:22.994385   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:23.008817   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:23.494328   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:23.507908   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:23.993448   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:24.007203   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:24.493207   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:24.497634   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:24.993422   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:25.016556   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:25.493933   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:25.557619   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:25.557674   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:25.607935   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:25.608009   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:25.669537   97653 logs.go:274] 0 containers: []
W0810 15:45:25.669559   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:25.669606   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:25.707729   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:25.707801   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:25.740917   97653 logs.go:274] 0 containers: []
W0810 15:45:25.740930   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:25.740987   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:25.778258   97653 logs.go:274] 0 containers: []
W0810 15:45:25.778269   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:25.778333   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:25.809882   97653 logs.go:274] 0 containers: []
W0810 15:45:25.809893   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:25.809952   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:25.842878   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:25.842903   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:25.842913   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:25.930019   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:25.930030   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:26.010195   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:26.010207   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:26.056250   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:26.056265   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:26.148401   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:26.148414   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:26.177538   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:26.177551   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:26.197342   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:26.197354   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:26.242540   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:26.242555   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:26.290177   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:26.290189   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:28.814908   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:28.830579   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:28.993860   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:29.029340   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:29.029404   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:29.067671   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:29.067754   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:29.114085   97653 logs.go:274] 0 containers: []
W0810 15:45:29.114098   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:29.114164   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:29.151504   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:29.151561   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:29.191251   97653 logs.go:274] 0 containers: []
W0810 15:45:29.191261   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:29.191310   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:29.227964   97653 logs.go:274] 0 containers: []
W0810 15:45:29.227980   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:29.228034   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:29.260663   97653 logs.go:274] 0 containers: []
W0810 15:45:29.260673   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:29.260746   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:29.293205   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:29.293243   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:29.293255   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:29.334254   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:29.334266   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:29.433615   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:29.433638   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:29.530303   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:29.530319   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:29.575774   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:29.575791   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:29.746277   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:29.746295   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:29.781815   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:29.781840   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:29.927084   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:29.927096   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:30.005222   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:30.005240   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:32.568899   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:32.584492   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:32.993670   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:33.054612   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:33.054680   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:33.088491   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:33.088569   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:33.121880   97653 logs.go:274] 0 containers: []
W0810 15:45:33.121892   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:33.121950   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:33.154739   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:33.154794   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:33.186862   97653 logs.go:274] 0 containers: []
W0810 15:45:33.186875   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:33.186955   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:33.219355   97653 logs.go:274] 0 containers: []
W0810 15:45:33.219365   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:33.219426   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:33.251986   97653 logs.go:274] 0 containers: []
W0810 15:45:33.251997   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:33.252065   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:33.284744   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:33.284764   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:33.284771   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:33.368065   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:33.368085   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:33.455194   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:33.455207   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:33.502087   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:33.502099   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:33.533641   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:33.533657   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:33.559127   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:33.559141   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:33.579038   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:33.579050   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:33.658494   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:33.658505   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:33.699825   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:33.699838   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:36.240957   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:36.255004   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:36.493462   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:36.551951   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:36.552033   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:36.584324   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:36.584393   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:36.616066   97653 logs.go:274] 0 containers: []
W0810 15:45:36.616079   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:36.616136   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:36.647951   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:36.648010   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:36.679207   97653 logs.go:274] 0 containers: []
W0810 15:45:36.679220   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:36.679273   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:36.711444   97653 logs.go:274] 0 containers: []
W0810 15:45:36.711454   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:36.711513   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:36.743028   97653 logs.go:274] 0 containers: []
W0810 15:45:36.743038   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:36.743086   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:36.775691   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:36.775715   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:36.775724   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:36.795152   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:36.795164   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:36.881912   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:36.881924   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:36.906041   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:36.906052   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:36.934091   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:36.934102   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:37.020410   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:37.020423   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:37.098437   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:37.098449   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:37.138012   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:37.138029   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:37.177242   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:37.177254   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:39.723926   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:39.735012   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:39.994157   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:40.032731   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:40.032825   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:40.067540   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:40.067592   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:40.106230   97653 logs.go:274] 0 containers: []
W0810 15:45:40.106249   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:40.106315   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:40.156247   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:40.156329   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:40.193884   97653 logs.go:274] 0 containers: []
W0810 15:45:40.193893   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:40.193938   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:40.239329   97653 logs.go:274] 0 containers: []
W0810 15:45:40.239342   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:40.239401   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:40.309068   97653 logs.go:274] 0 containers: []
W0810 15:45:40.309087   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:40.309135   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:40.353572   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:40.353671   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:40.353697   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:40.386933   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:40.386947   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:40.499090   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:40.508435   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:40.547184   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:40.547221   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:40.670933   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:40.670959   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:40.725315   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:40.725354   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:40.825473   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:40.825497   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:40.881850   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:40.881865   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:40.944075   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:40.944090   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:43.477212   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:43.483030   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:43.494422   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:43.546946   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:43.547011   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:43.592580   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:43.592656   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:43.649171   97653 logs.go:274] 0 containers: []
W0810 15:45:43.649186   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:43.649245   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:43.701618   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:43.701681   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:43.739387   97653 logs.go:274] 0 containers: []
W0810 15:45:43.739403   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:43.739455   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:43.780765   97653 logs.go:274] 0 containers: []
W0810 15:45:43.780780   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:43.780826   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:43.832099   97653 logs.go:274] 0 containers: []
W0810 15:45:43.832132   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:43.832274   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:43.948416   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:43.948456   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:43.948473   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:44.149844   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:44.149858   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:44.196383   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:44.196412   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:44.265370   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:44.265390   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:44.360926   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:44.360941   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:44.546488   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:44.546506   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:44.771394   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:44.771412   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:44.799001   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:44.799019   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:44.913703   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:44.913722   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:47.474620   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:47.485161   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:47.493399   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:47.564145   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:47.564217   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:47.602353   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:47.602416   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:47.641086   97653 logs.go:274] 0 containers: []
W0810 15:45:47.641098   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:47.641148   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:47.689761   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:47.689982   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:47.726761   97653 logs.go:274] 0 containers: []
W0810 15:45:47.726773   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:47.726843   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:47.760796   97653 logs.go:274] 0 containers: []
W0810 15:45:47.760807   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:47.760852   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:47.796136   97653 logs.go:274] 0 containers: []
W0810 15:45:47.796149   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:47.796222   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:47.848536   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:47.848573   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:47.848593   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:47.906410   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:47.906423   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:48.000661   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:48.000675   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:48.030485   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:48.030496   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:48.051795   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:48.051808   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:48.142798   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:48.142816   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:48.193788   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:48.193801   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:48.221863   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:48.221949   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:48.317497   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:48.317510   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:50.878403   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:50.888773   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:50.994755   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:51.096169   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:51.096251   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:51.144537   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:51.144625   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:51.180544   97653 logs.go:274] 0 containers: []
W0810 15:45:51.180563   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:51.180626   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:51.213663   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:51.213713   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:51.245680   97653 logs.go:274] 0 containers: []
W0810 15:45:51.245690   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:51.245775   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:51.287946   97653 logs.go:274] 0 containers: []
W0810 15:45:51.287957   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:51.288013   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:51.320770   97653 logs.go:274] 0 containers: []
W0810 15:45:51.320782   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:51.320831   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:51.353568   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:51.353596   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:51.353605   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:51.373516   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:51.373530   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:51.415514   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:51.415527   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:51.440509   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:51.440525   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:51.538429   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:51.538444   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:51.590472   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:51.590487   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:51.625410   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:51.625422   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:51.713287   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:51.713308   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:51.795408   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:51.795420   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:54.337239   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:54.352535   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:54.494231   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:54.562255   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:54.562313   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:54.599562   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:54.599657   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:54.632327   97653 logs.go:274] 0 containers: []
W0810 15:45:54.632343   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:54.632390   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:54.665205   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:54.665262   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:54.697803   97653 logs.go:274] 0 containers: []
W0810 15:45:54.697821   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:54.697867   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:54.733304   97653 logs.go:274] 0 containers: []
W0810 15:45:54.733316   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:54.733371   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:54.767219   97653 logs.go:274] 0 containers: []
W0810 15:45:54.767231   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:54.767281   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:54.802115   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:54.802141   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:54.802151   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:54.895975   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:54.895991   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:54.985548   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:54.985569   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:55.084634   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:55.084650   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:45:55.114987   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:55.115008   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:55.136389   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:55.136401   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:55.178983   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:55.178997   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:55.229007   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:55.229019   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:55.278272   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:55.278293   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:57.805592   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:45:57.821617   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:45:57.994217   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:45:58.060323   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:45:58.060378   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:45:58.092440   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:45:58.092517   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:45:58.123900   97653 logs.go:274] 0 containers: []
W0810 15:45:58.123909   97653 logs.go:276] No container was found matching "coredns"
I0810 15:45:58.123953   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:45:58.155802   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:45:58.155863   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:45:58.192972   97653 logs.go:274] 0 containers: []
W0810 15:45:58.192982   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:45:58.193035   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:45:58.225109   97653 logs.go:274] 0 containers: []
W0810 15:45:58.225119   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:45:58.225165   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:45:58.256616   97653 logs.go:274] 0 containers: []
W0810 15:45:58.256637   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:45:58.256684   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:45:58.288692   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:45:58.288712   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:45:58.288719   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:45:58.313462   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:45:58.313475   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:45:58.333126   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:45:58.333139   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:45:58.571994   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:45:58.572007   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:45:58.621350   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:45:58.621362   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:45:58.668561   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:45:58.668582   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:45:58.752371   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:45:58.752388   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:45:58.798831   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:45:58.798843   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:45:58.887572   97653 logs.go:123] Gathering logs for container status ...
I0810 15:45:58.887586   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:01.415429   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:01.430615   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:01.494346   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:01.558106   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:01.558168   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:01.591830   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:01.591900   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:01.622870   97653 logs.go:274] 0 containers: []
W0810 15:46:01.622880   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:01.622926   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:01.655492   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:01.655560   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:01.687522   97653 logs.go:274] 0 containers: []
W0810 15:46:01.687535   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:01.687622   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:01.723503   97653 logs.go:274] 0 containers: []
W0810 15:46:01.723516   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:01.723567   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:01.755523   97653 logs.go:274] 0 containers: []
W0810 15:46:01.755534   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:01.755579   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:01.789803   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:46:01.789829   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:01.789840   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:01.835468   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:46:01.835480   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:46:01.882270   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:01.882283   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:01.909585   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:01.909606   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:01.988998   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:01.989011   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:02.010733   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:02.010750   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:02.056977   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:02.056990   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:02.156212   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:02.156236   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:02.182276   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:02.182291   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:04.773411   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:04.779243   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:04.994042   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:05.053718   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:05.053775   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:05.086036   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:05.086114   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:05.119058   97653 logs.go:274] 0 containers: []
W0810 15:46:05.119068   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:05.119126   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:05.151323   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:05.151394   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:05.183379   97653 logs.go:274] 0 containers: []
W0810 15:46:05.183392   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:05.183460   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:05.215681   97653 logs.go:274] 0 containers: []
W0810 15:46:05.215694   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:05.215759   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:05.248147   97653 logs.go:274] 0 containers: []
W0810 15:46:05.248159   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:05.248210   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:05.280136   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:46:05.280160   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:05.280169   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:05.300168   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:05.300179   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:05.342721   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:05.342736   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:05.384579   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:05.384592   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:05.480427   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:46:05.480440   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:46:05.526062   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:05.526074   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:05.552609   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:05.552621   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:05.582742   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:05.582755   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:05.666592   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:05.666606   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:08.245632   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:08.257139   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:08.493669   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:08.554983   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:08.555042   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:08.587309   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:08.587383   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:08.618793   97653 logs.go:274] 0 containers: []
W0810 15:46:08.618812   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:08.618859   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:08.651215   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:08.651265   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:08.683416   97653 logs.go:274] 0 containers: []
W0810 15:46:08.683427   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:08.683480   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:08.715210   97653 logs.go:274] 0 containers: []
W0810 15:46:08.715222   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:08.715276   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:08.747277   97653 logs.go:274] 0 containers: []
W0810 15:46:08.747286   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:08.747334   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:08.779208   97653 logs.go:274] 1 containers: [89e097edd23d]
I0810 15:46:08.779232   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:08.779239   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:08.872161   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:46:08.872175   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:46:08.917845   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:08.917857   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:08.946283   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:08.946295   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:09.031415   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:09.031430   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:09.124675   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:09.124687   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:09.168937   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:09.168948   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:09.188296   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:09.188307   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:09.227808   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:09.227819   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:11.752681   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:11.763118   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:11.993636   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:12.046600   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:12.046659   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:12.086903   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:12.086965   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:12.118672   97653 logs.go:274] 0 containers: []
W0810 15:46:12.118685   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:12.118744   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:12.150995   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:12.151057   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:12.183888   97653 logs.go:274] 0 containers: []
W0810 15:46:12.183897   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:12.183943   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:12.216614   97653 logs.go:274] 0 containers: []
W0810 15:46:12.216625   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:12.216687   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:12.249099   97653 logs.go:274] 0 containers: []
W0810 15:46:12.249109   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:12.249168   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:12.281354   97653 logs.go:274] 2 containers: [6d16409166db 89e097edd23d]
I0810 15:46:12.281399   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:12.281413   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:12.322069   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:12.322092   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:12.363501   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:12.363512   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:12.458536   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:46:12.458551   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:46:12.503982   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:12.504004   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:12.523400   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:12.523412   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:12.609814   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:12.609828   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:12.634176   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:12.634187   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:12.662000   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:12.662011   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:12.749006   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:12.749021   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:15.285712   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:15.296686   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:15.494246   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:15.564879   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:15.564936   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:15.602645   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:15.602700   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:15.634514   97653 logs.go:274] 0 containers: []
W0810 15:46:15.634528   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:15.634580   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:15.666886   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:15.666945   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:15.698669   97653 logs.go:274] 0 containers: []
W0810 15:46:15.698682   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:15.698754   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:15.731375   97653 logs.go:274] 0 containers: []
W0810 15:46:15.731385   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:15.731432   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:15.762796   97653 logs.go:274] 0 containers: []
W0810 15:46:15.762819   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:15.762866   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:15.795392   97653 logs.go:274] 2 containers: [6d16409166db 89e097edd23d]
I0810 15:46:15.795416   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:15.795423   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:15.815712   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:15.815724   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:15.856334   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:15.856346   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:15.884797   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:15.884808   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:15.968806   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:15.968823   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:16.046453   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:16.046465   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:16.086333   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:16.086345   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:16.180644   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:16.180710   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:16.217608   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:46:16.217620   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:46:16.263784   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:16.263796   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:18.787719   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:18.802908   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:18.994394   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:19.074528   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:19.074592   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:19.108921   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:19.108970   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:19.142345   97653 logs.go:274] 0 containers: []
W0810 15:46:19.142355   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:19.142404   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:19.176142   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:19.176210   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:19.213980   97653 logs.go:274] 0 containers: []
W0810 15:46:19.213990   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:19.214049   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:19.248566   97653 logs.go:274] 0 containers: []
W0810 15:46:19.248578   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:19.248638   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:19.281480   97653 logs.go:274] 0 containers: []
W0810 15:46:19.281493   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:19.281554   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:19.316177   97653 logs.go:274] 2 containers: [6d16409166db 89e097edd23d]
I0810 15:46:19.316221   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:19.316228   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:19.404352   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:19.404367   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:19.424663   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:19.424677   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:19.506739   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:19.506750   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:19.557181   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:19.557193   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:19.592942   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:19.592958   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:19.622200   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:19.622212   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:19.662892   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:19.662904   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:19.755361   97653 logs.go:123] Gathering logs for kube-controller-manager [89e097edd23d] ...
I0810 15:46:19.755374   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 89e097edd23d"
I0810 15:46:19.805729   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:19.805741   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:22.329657   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:22.340654   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:22.493953   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:22.543870   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:22.543936   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:22.578385   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:22.578448   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:22.612281   97653 logs.go:274] 0 containers: []
W0810 15:46:22.612293   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:22.612345   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:22.646395   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:22.646477   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:22.679937   97653 logs.go:274] 0 containers: []
W0810 15:46:22.679948   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:22.679998   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:22.713349   97653 logs.go:274] 0 containers: []
W0810 15:46:22.713359   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:22.713411   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:22.747041   97653 logs.go:274] 0 containers: []
W0810 15:46:22.747058   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:22.747122   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:22.780644   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:22.780667   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:22.780683   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:22.873255   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:22.873266   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:22.917085   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:22.917098   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:23.017603   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:23.017629   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:23.045144   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:23.045163   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:23.074973   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:23.074986   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:23.163965   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:23.163978   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:23.184240   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:23.184257   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:23.225826   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:23.225847   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:25.775957   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:25.796687   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:25.994438   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:26.095373   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:26.095443   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:26.130964   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:26.131025   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:26.165889   97653 logs.go:274] 0 containers: []
W0810 15:46:26.165903   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:26.165953   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:26.199829   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:26.199899   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:26.233467   97653 logs.go:274] 0 containers: []
W0810 15:46:26.233480   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:26.233531   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:26.266236   97653 logs.go:274] 0 containers: []
W0810 15:46:26.266248   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:26.266292   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:26.299665   97653 logs.go:274] 0 containers: []
W0810 15:46:26.299677   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:26.299752   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:26.343682   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:26.343712   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:26.343720   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:26.366347   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:26.366381   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:26.604030   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:26.604075   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:26.687431   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:26.687452   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:26.741407   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:26.741427   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:26.848447   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:26.848460   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:26.887571   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:26.887583   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:26.927502   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:26.927514   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:27.019878   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:27.019891   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:29.565575   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:29.595218   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:29.993880   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:30.059146   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:30.059206   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:30.092344   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:30.092440   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:30.128217   97653 logs.go:274] 0 containers: []
W0810 15:46:30.128227   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:30.128280   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:30.159923   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:30.159978   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:30.190959   97653 logs.go:274] 0 containers: []
W0810 15:46:30.190968   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:30.191028   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:30.222003   97653 logs.go:274] 0 containers: []
W0810 15:46:30.222013   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:30.222055   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:30.253291   97653 logs.go:274] 0 containers: []
W0810 15:46:30.253302   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:30.253349   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:30.285738   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:30.285759   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:30.285769   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:30.381427   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:30.381456   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:30.426799   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:30.426812   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:30.455228   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:30.455239   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:30.542835   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:30.542853   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:30.563046   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:30.563057   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:30.603226   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:30.603253   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:30.682579   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:30.682591   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:30.722929   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:30.722942   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:33.247809   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:33.260048   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:33.493649   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:33.559851   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:33.559916   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:33.592187   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:33.592244   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:33.623556   97653 logs.go:274] 0 containers: []
W0810 15:46:33.623566   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:33.623645   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:33.655219   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:33.655280   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:33.688138   97653 logs.go:274] 0 containers: []
W0810 15:46:33.688150   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:33.688200   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:33.719630   97653 logs.go:274] 0 containers: []
W0810 15:46:33.719642   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:33.719705   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:33.754412   97653 logs.go:274] 0 containers: []
W0810 15:46:33.754426   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:33.754485   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:33.785776   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:33.785796   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:33.785805   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:33.810146   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:33.810157   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:33.838437   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:33.838449   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:33.921586   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:33.921598   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:33.999801   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:33.999812   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:34.040490   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:34.040501   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:34.085871   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:34.085882   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:34.105435   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:34.105455   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:34.144947   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:34.144958   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:36.738117   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:36.749123   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:36.994019   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:37.056928   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:37.056990   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:37.090796   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:37.090861   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:37.122051   97653 logs.go:274] 0 containers: []
W0810 15:46:37.122066   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:37.122126   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:37.154012   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:37.154078   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:37.185529   97653 logs.go:274] 0 containers: []
W0810 15:46:37.185539   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:37.185612   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:37.216540   97653 logs.go:274] 0 containers: []
W0810 15:46:37.216550   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:37.216603   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:37.248140   97653 logs.go:274] 0 containers: []
W0810 15:46:37.248159   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:37.248204   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:37.280158   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:37.280189   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:37.280199   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:37.308355   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:37.308367   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:37.334250   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:37.334277   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:37.442512   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:37.442529   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:37.484255   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:37.484270   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:37.529543   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:37.529557   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:37.555330   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:37.555342   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:37.641205   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:37.641217   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:37.680701   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:37.680712   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:40.274910   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:40.286365   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:40.494393   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:40.573911   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:40.573966   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:40.605279   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:40.605333   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:40.637050   97653 logs.go:274] 0 containers: []
W0810 15:46:40.637069   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:40.637121   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:40.669285   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:40.669353   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:40.701559   97653 logs.go:274] 0 containers: []
W0810 15:46:40.701571   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:40.701626   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:40.733069   97653 logs.go:274] 0 containers: []
W0810 15:46:40.733080   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:40.733131   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:40.765933   97653 logs.go:274] 0 containers: []
W0810 15:46:40.765944   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:40.766002   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:40.798724   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:40.798758   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:40.798766   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:40.881936   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:40.881947   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:40.936954   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:40.936967   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:40.984260   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:40.984274   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:41.121372   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:41.121395   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:41.179359   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:41.179384   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:41.308831   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:41.308846   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:41.337159   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:41.337176   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:41.433130   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:41.433152   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:44.023387   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:44.040440   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:44.494416   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:44.557335   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:44.557400   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:44.590461   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:44.590532   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:44.623288   97653 logs.go:274] 0 containers: []
W0810 15:46:44.623307   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:44.623362   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:44.656476   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:44.656557   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:44.688804   97653 logs.go:274] 0 containers: []
W0810 15:46:44.688815   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:44.688878   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:44.721185   97653 logs.go:274] 0 containers: []
W0810 15:46:44.721195   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:44.721237   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:44.753660   97653 logs.go:274] 0 containers: []
W0810 15:46:44.753675   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:44.753746   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:44.786627   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:44.786653   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:44.786661   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:44.806858   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:44.806870   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:44.849682   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:44.849697   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:44.878228   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:44.878240   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:44.970845   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:44.970860   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:45.083677   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:45.083689   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:45.125155   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:45.125166   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:45.237035   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:45.237049   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:45.288991   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:45.289003   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:47.814811   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:47.829018   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:47.993606   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:48.055528   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:48.055584   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:48.088036   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:48.088101   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:48.120169   97653 logs.go:274] 0 containers: []
W0810 15:46:48.120179   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:48.120231   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:48.153444   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:48.153520   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:48.185292   97653 logs.go:274] 0 containers: []
W0810 15:46:48.185301   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:48.185350   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:48.216543   97653 logs.go:274] 0 containers: []
W0810 15:46:48.216570   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:48.216628   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:48.249523   97653 logs.go:274] 0 containers: []
W0810 15:46:48.249538   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:48.249599   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:48.281643   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:48.281661   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:48.281670   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:48.301626   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:48.301644   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:48.384405   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:48.384417   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:48.426051   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:48.426062   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:48.460013   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:48.460025   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:48.494245   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:48.494259   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:48.586238   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:48.586251   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:48.635034   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:48.635046   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:48.731691   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:48.731704   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:51.278323   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:51.285224   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:51.494197   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:51.574000   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:51.574077   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:51.628931   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:51.629139   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:51.680253   97653 logs.go:274] 0 containers: []
W0810 15:46:51.680266   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:51.680322   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:51.726629   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:51.726686   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:51.764036   97653 logs.go:274] 0 containers: []
W0810 15:46:51.764048   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:51.764105   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:51.802660   97653 logs.go:274] 0 containers: []
W0810 15:46:51.802674   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:51.802726   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:51.835639   97653 logs.go:274] 0 containers: []
W0810 15:46:51.835652   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:51.835706   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:51.869323   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:51.869346   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:51.869353   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:51.909956   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:51.909968   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:51.952666   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:51.952678   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:51.998871   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:51.998883   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:52.021891   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:52.021902   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:52.108765   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:52.108780   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:52.191180   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:52.191193   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:52.218316   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:52.218327   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:52.237560   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:52.237571   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:54.834049   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:54.846408   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:54.993991   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:55.073993   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:55.074059   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:55.106478   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:55.106550   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:55.138140   97653 logs.go:274] 0 containers: []
W0810 15:46:55.138161   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:55.138228   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:55.171095   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:55.171152   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:55.203030   97653 logs.go:274] 0 containers: []
W0810 15:46:55.203039   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:55.203095   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:55.236260   97653 logs.go:274] 0 containers: []
W0810 15:46:55.236270   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:55.236313   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:55.267831   97653 logs.go:274] 0 containers: []
W0810 15:46:55.267843   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:55.267900   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:55.299697   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:55.299718   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:55.299729   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:55.383056   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:55.383069   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:55.422632   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:55.422644   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:55.466222   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:55.466233   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:55.510817   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:55.510829   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:46:55.542427   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:55.542438   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:55.562391   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:55.562404   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:55.642293   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:55.642305   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:55.737775   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:55.737787   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:58.263104   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:46:58.276652   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:46:58.494383   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:46:58.557280   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:46:58.557345   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:46:58.589870   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:46:58.589938   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:46:58.621201   97653 logs.go:274] 0 containers: []
W0810 15:46:58.621214   97653 logs.go:276] No container was found matching "coredns"
I0810 15:46:58.621273   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:46:58.653740   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:46:58.653803   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:46:58.685631   97653 logs.go:274] 0 containers: []
W0810 15:46:58.685640   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:46:58.685691   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:46:58.717372   97653 logs.go:274] 0 containers: []
W0810 15:46:58.717383   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:46:58.717444   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:46:58.748981   97653 logs.go:274] 0 containers: []
W0810 15:46:58.748991   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:46:58.749051   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:46:58.780747   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:46:58.780769   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:46:58.780778   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:46:58.864531   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:46:58.864543   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:46:58.944857   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:46:58.944868   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:46:58.985524   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:46:58.985535   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:46:59.009076   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:46:59.009089   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:46:59.028870   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:46:59.028882   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:46:59.067753   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:46:59.067764   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:46:59.163254   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:46:59.163266   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:46:59.208131   97653 logs.go:123] Gathering logs for container status ...
I0810 15:46:59.208143   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:01.737750   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:01.750627   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:01.994109   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:02.054960   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:02.055018   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:02.086783   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:02.086848   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:02.118783   97653 logs.go:274] 0 containers: []
W0810 15:47:02.118797   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:02.118873   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:02.151666   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:02.151716   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:02.184595   97653 logs.go:274] 0 containers: []
W0810 15:47:02.184607   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:02.184676   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:02.216521   97653 logs.go:274] 0 containers: []
W0810 15:47:02.216533   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:02.216583   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:02.248128   97653 logs.go:274] 0 containers: []
W0810 15:47:02.248156   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:02.248205   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:02.279761   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:02.279780   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:02.279793   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:02.299544   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:02.299556   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:02.395758   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:02.395772   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:02.421662   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:02.421676   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:02.449252   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:02.449264   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:02.535988   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:02.536007   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:02.614463   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:02.614474   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:02.654084   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:02.654098   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:02.697211   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:02.697223   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:05.242850   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:05.255154   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:05.493640   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:05.770462   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:05.770544   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:05.809113   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:05.809169   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:05.841634   97653 logs.go:274] 0 containers: []
W0810 15:47:05.841644   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:05.841697   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:05.873265   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:05.873325   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:05.905223   97653 logs.go:274] 0 containers: []
W0810 15:47:05.905242   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:05.905316   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:05.937136   97653 logs.go:274] 0 containers: []
W0810 15:47:05.937148   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:05.937207   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:05.969476   97653 logs.go:274] 0 containers: []
W0810 15:47:05.969486   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:05.969552   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:06.002858   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:06.002884   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:06.002895   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:06.083148   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:06.083160   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:06.122982   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:06.123012   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:06.163538   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:06.163558   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:06.192290   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:06.192301   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:06.279368   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:06.279380   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:06.298846   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:06.298857   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:06.401211   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:06.401230   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:06.450223   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:06.450240   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:08.985102   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:08.999282   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:09.493738   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:09.557239   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:09.557302   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:09.589304   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:09.589379   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:09.620415   97653 logs.go:274] 0 containers: []
W0810 15:47:09.620430   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:09.620499   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:09.651674   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:09.651749   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:09.682458   97653 logs.go:274] 0 containers: []
W0810 15:47:09.682471   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:09.682522   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:09.713451   97653 logs.go:274] 0 containers: []
W0810 15:47:09.713465   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:09.713513   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:09.745688   97653 logs.go:274] 0 containers: []
W0810 15:47:09.745698   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:09.745764   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:09.777204   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:09.777222   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:09.777229   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:09.874975   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:09.874987   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:09.901071   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:09.901092   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:09.928919   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:09.928932   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:10.014459   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:10.014473   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:10.033652   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:10.033664   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:10.111114   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:10.111131   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:10.150318   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:10.150329   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:10.190680   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:10.190693   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:12.737562   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:12.757953   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:12.993845   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:13.059060   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:13.059134   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:13.091056   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:13.091125   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:13.123037   97653 logs.go:274] 0 containers: []
W0810 15:47:13.123048   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:13.123110   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:13.154886   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:13.154948   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:13.186268   97653 logs.go:274] 0 containers: []
W0810 15:47:13.186278   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:13.186344   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:13.217879   97653 logs.go:274] 0 containers: []
W0810 15:47:13.217892   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:13.217938   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:13.249256   97653 logs.go:274] 0 containers: []
W0810 15:47:13.249269   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:13.249318   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:13.281187   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:13.281219   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:13.281229   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:13.305220   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:13.305232   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:13.332744   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:13.332756   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:13.373141   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:13.373152   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:13.470060   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:13.470079   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:13.515213   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:13.515224   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:13.557937   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:13.557949   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:13.645471   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:13.645484   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:13.664827   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:13.664839   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:16.243491   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:16.255274   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:16.493800   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:16.563077   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:16.563154   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:16.598464   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:16.598520   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:16.629907   97653 logs.go:274] 0 containers: []
W0810 15:47:16.629921   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:16.629975   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:16.661687   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:16.661759   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:16.693411   97653 logs.go:274] 0 containers: []
W0810 15:47:16.693421   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:16.693468   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:16.724744   97653 logs.go:274] 0 containers: []
W0810 15:47:16.724754   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:16.724812   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:16.756160   97653 logs.go:274] 0 containers: []
W0810 15:47:16.756173   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:16.756222   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:16.790436   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:16.790458   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:16.790468   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:16.831623   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:16.831634   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:16.931558   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:16.931570   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:16.959688   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:16.959700   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:17.043708   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:17.043729   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:17.087655   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:17.087667   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:17.132855   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:17.132865   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:17.156574   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:17.156586   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:17.176171   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:17.176181   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:19.755782   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:19.760668   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:19.994509   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:20.114590   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:20.114786   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:20.170072   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:20.170134   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:20.201758   97653 logs.go:274] 0 containers: []
W0810 15:47:20.201771   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:20.201836   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:20.234110   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:20.234166   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:20.265522   97653 logs.go:274] 0 containers: []
W0810 15:47:20.265534   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:20.265592   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:20.297036   97653 logs.go:274] 0 containers: []
W0810 15:47:20.297045   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:20.297093   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:20.328071   97653 logs.go:274] 0 containers: []
W0810 15:47:20.328085   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:20.328133   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:20.359848   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:20.359880   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:20.359887   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:20.447272   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:20.447290   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:20.531027   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:20.531048   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:20.572464   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:20.572477   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:20.596392   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:20.596404   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:20.625461   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:20.625476   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:20.644677   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:20.644694   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:20.685068   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:20.685089   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:20.783515   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:20.783527   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:23.330792   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:23.343738   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:23.494549   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:23.561666   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:23.561745   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:23.594528   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:23.594580   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:23.625888   97653 logs.go:274] 0 containers: []
W0810 15:47:23.625898   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:23.625945   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:23.658010   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:23.658080   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:23.689666   97653 logs.go:274] 0 containers: []
W0810 15:47:23.689679   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:23.689732   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:23.722156   97653 logs.go:274] 0 containers: []
W0810 15:47:23.722171   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:23.722230   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:23.755099   97653 logs.go:274] 0 containers: []
W0810 15:47:23.755109   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:23.755162   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:23.788182   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:23.788200   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:23.788207   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:23.809107   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:23.809121   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:23.893395   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:23.893405   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:23.935710   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:23.935723   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:23.979923   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:23.979936   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:24.029102   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:24.029121   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:24.115338   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:24.115351   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:24.215121   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:24.215133   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:24.239594   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:24.239615   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:26.768804   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:26.781409   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:26.994348   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:27.064833   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:27.064881   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:27.098121   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:27.098175   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:27.130821   97653 logs.go:274] 0 containers: []
W0810 15:47:27.130834   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:27.130880   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:27.164242   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:27.164308   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:27.196360   97653 logs.go:274] 0 containers: []
W0810 15:47:27.196372   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:27.196419   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:27.234343   97653 logs.go:274] 0 containers: []
W0810 15:47:27.234356   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:27.234403   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:27.266221   97653 logs.go:274] 0 containers: []
W0810 15:47:27.266233   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:27.266285   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:27.298051   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:27.298085   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:27.298095   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:27.386655   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:27.386667   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:27.469245   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:27.469259   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:27.512683   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:27.512696   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:27.541694   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:27.541712   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:27.570397   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:27.570409   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:27.590933   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:27.590945   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:27.632760   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:27.632776   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:27.734640   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:27.734663   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:30.281770   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:30.296480   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:30.494181   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:30.631388   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:30.631493   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:30.693494   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:30.693568   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:30.726870   97653 logs.go:274] 0 containers: []
W0810 15:47:30.726881   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:30.726931   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:30.760260   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:30.760328   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:30.792958   97653 logs.go:274] 0 containers: []
W0810 15:47:30.792971   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:30.793025   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:30.827975   97653 logs.go:274] 0 containers: []
W0810 15:47:30.827986   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:30.828042   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:30.860315   97653 logs.go:274] 0 containers: []
W0810 15:47:30.860330   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:30.860384   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:30.892238   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:30.892261   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:30.892269   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:30.912188   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:30.912201   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:30.951903   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:30.951923   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:31.000061   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:31.000074   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:31.024463   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:31.024477   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:31.113653   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:31.113669   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:31.195286   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:31.195299   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:31.239514   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:31.239526   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:31.345587   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:31.345601   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:33.876065   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:33.889888   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:33.994520   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:34.062100   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:34.062174   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:34.094685   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:34.094745   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:34.125728   97653 logs.go:274] 0 containers: []
W0810 15:47:34.125741   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:34.125808   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:34.158736   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:34.158812   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:34.191548   97653 logs.go:274] 0 containers: []
W0810 15:47:34.191562   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:34.191641   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:34.224574   97653 logs.go:274] 0 containers: []
W0810 15:47:34.224586   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:34.224643   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:34.256945   97653 logs.go:274] 0 containers: []
W0810 15:47:34.256957   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:34.257024   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:34.290342   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:34.290366   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:34.290374   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:34.331997   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:34.332031   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:34.356499   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:34.356512   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:34.384220   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:34.384232   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:34.425412   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:34.425423   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:34.523273   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:34.523285   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:34.595553   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:34.595632   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:34.715328   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:34.715340   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:34.734382   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:34.734393   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:37.312624   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:37.325563   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:37.494143   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:37.555249   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:37.555311   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:37.586826   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:37.586887   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:37.618237   97653 logs.go:274] 0 containers: []
W0810 15:47:37.618248   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:37.618300   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:37.650030   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:37.650095   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:37.682101   97653 logs.go:274] 0 containers: []
W0810 15:47:37.682111   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:37.682166   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:37.713508   97653 logs.go:274] 0 containers: []
W0810 15:47:37.713518   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:37.713565   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:37.744919   97653 logs.go:274] 0 containers: []
W0810 15:47:37.744931   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:37.744985   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:37.781470   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:37.781495   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:37.781502   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:37.864543   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:37.864555   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:37.941978   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:37.941989   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:37.983838   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:37.983849   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:38.085777   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:38.085789   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:38.131079   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:38.131090   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:38.158534   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:38.158546   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:38.177716   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:38.177727   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:38.217289   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:38.217300   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:40.742261   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:40.747952   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:40.993529   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:41.053974   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:41.054045   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:41.086215   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:41.086267   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:41.117849   97653 logs.go:274] 0 containers: []
W0810 15:47:41.117859   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:41.117924   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:41.149763   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:41.149817   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:41.180431   97653 logs.go:274] 0 containers: []
W0810 15:47:41.180450   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:41.180512   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:41.211046   97653 logs.go:274] 0 containers: []
W0810 15:47:41.211067   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:41.211121   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:41.242961   97653 logs.go:274] 0 containers: []
W0810 15:47:41.242970   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:41.243016   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:41.275402   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:41.275423   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:41.275446   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:41.315370   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:41.315381   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:41.356901   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:41.356912   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:41.381765   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:41.381781   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:41.409253   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:41.409266   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:41.490913   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:41.490924   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:41.510044   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:41.510055   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:41.592860   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:41.592873   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:41.701311   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:41.701324   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:44.247493   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:44.263700   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:44.494385   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:44.560023   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:44.560073   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:44.592048   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:44.592102   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:44.623006   97653 logs.go:274] 0 containers: []
W0810 15:47:44.623015   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:44.623061   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:44.655591   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:44.655691   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:44.687872   97653 logs.go:274] 0 containers: []
W0810 15:47:44.687882   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:44.687929   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:44.728010   97653 logs.go:274] 0 containers: []
W0810 15:47:44.728024   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:44.728078   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:44.760037   97653 logs.go:274] 0 containers: []
W0810 15:47:44.760049   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:44.760100   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:44.791569   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:44.791610   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:44.791621   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:44.836731   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:44.836744   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:44.861006   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:44.861018   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:44.943549   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:44.943565   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:45.021063   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:45.021075   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:45.063542   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:45.063554   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:45.167696   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:45.167717   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:45.197025   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:45.197036   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:45.215917   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:45.215930   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:47.756320   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:47.768767   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:47.993464   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:48.052339   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:48.052396   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:48.083885   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:48.083957   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:48.115481   97653 logs.go:274] 0 containers: []
W0810 15:47:48.115491   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:48.115542   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:48.146777   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:48.146831   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:48.177964   97653 logs.go:274] 0 containers: []
W0810 15:47:48.177974   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:48.178020   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:48.214355   97653 logs.go:274] 0 containers: []
W0810 15:47:48.214367   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:48.214432   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:48.245379   97653 logs.go:274] 0 containers: []
W0810 15:47:48.245391   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:48.245442   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:48.277075   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:48.277096   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:48.277104   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:48.362951   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:48.362967   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:48.408083   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:48.408096   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:48.435767   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:48.435779   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:48.454655   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:48.454667   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:48.551389   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:48.551404   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:48.600304   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:48.600323   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:48.645089   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:48.645101   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:48.747894   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:48.747907   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:51.271822   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:51.290136   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:51.493584   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:51.562541   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:51.562597   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:51.594568   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:51.594622   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:51.626102   97653 logs.go:274] 0 containers: []
W0810 15:47:51.626114   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:51.626168   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:51.657903   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:51.657979   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:51.688722   97653 logs.go:274] 0 containers: []
W0810 15:47:51.688736   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:51.688789   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:51.720336   97653 logs.go:274] 0 containers: []
W0810 15:47:51.720345   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:51.720398   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:51.751638   97653 logs.go:274] 0 containers: []
W0810 15:47:51.751648   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:51.751693   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:51.783116   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:51.783136   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:51.783144   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:51.802661   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:51.802673   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:51.841835   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:51.841846   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:51.884120   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:51.884132   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:51.930348   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:51.930360   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:51.958104   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:51.958115   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:52.042694   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:52.042709   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:52.120632   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:52.120643   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:52.223374   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:52.223387   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:54.748201   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:54.760833   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:54.994081   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:55.032514   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:55.032581   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:55.064259   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:55.064331   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:55.095918   97653 logs.go:274] 0 containers: []
W0810 15:47:55.095933   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:55.095980   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:55.131767   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:55.131822   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:55.164288   97653 logs.go:274] 0 containers: []
W0810 15:47:55.164301   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:55.164353   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:55.195509   97653 logs.go:274] 0 containers: []
W0810 15:47:55.195519   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:55.195570   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:55.227322   97653 logs.go:274] 0 containers: []
W0810 15:47:55.227333   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:55.227378   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:55.259688   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:55.259712   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:55.259720   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:55.336715   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:55.336727   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:55.381452   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:55.381463   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:47:55.404694   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:55.404712   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:55.432267   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:55.432280   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:55.518430   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:55.518442   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:55.541102   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:55.541121   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:55.580816   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:55.580829   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:55.624380   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:55.624392   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:58.239216   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:47:58.252152   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:47:58.493550   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:47:58.556243   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:47:58.556314   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:47:58.588914   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:47:58.588984   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:47:58.625943   97653 logs.go:274] 0 containers: []
W0810 15:47:58.625956   97653 logs.go:276] No container was found matching "coredns"
I0810 15:47:58.626015   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:47:58.657460   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:47:58.657530   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:47:58.688277   97653 logs.go:274] 0 containers: []
W0810 15:47:58.688290   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:47:58.688336   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:47:58.720791   97653 logs.go:274] 0 containers: []
W0810 15:47:58.720812   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:47:58.720863   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:47:58.752637   97653 logs.go:274] 0 containers: []
W0810 15:47:58.752647   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:47:58.752701   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:47:58.784235   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:47:58.784254   97653 logs.go:123] Gathering logs for container status ...
I0810 15:47:58.784261   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:47:58.812512   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:47:58.812524   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:47:58.900476   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:47:58.900489   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:47:58.920129   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:47:58.920141   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:47:58.997618   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:47:58.997629   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:47:59.037994   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:47:59.038005   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:47:59.082193   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:47:59.082204   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:47:59.186926   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:47:59.186947   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:47:59.232405   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:47:59.232416   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:01.755793   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:01.770076   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:01.994315   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:02.061400   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:02.061454   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:02.096462   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:02.096528   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:02.129040   97653 logs.go:274] 0 containers: []
W0810 15:48:02.129053   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:02.129104   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:02.162319   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:02.162364   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:02.194663   97653 logs.go:274] 0 containers: []
W0810 15:48:02.194677   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:02.194735   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:02.229383   97653 logs.go:274] 0 containers: []
W0810 15:48:02.229403   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:02.229451   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:02.262095   97653 logs.go:274] 0 containers: []
W0810 15:48:02.262105   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:02.262150   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:02.295055   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:02.295074   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:02.295081   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:02.341742   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:02.341755   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:02.451495   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:02.451508   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:02.498359   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:02.498379   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:02.526998   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:02.527015   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:02.549796   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:02.549809   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:02.632053   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:02.632065   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:02.674826   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:02.674838   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:02.699809   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:02.699823   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:05.289442   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:05.304020   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:05.493691   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:05.566247   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:05.566303   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:05.598396   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:05.598455   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:05.630727   97653 logs.go:274] 0 containers: []
W0810 15:48:05.630744   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:05.630833   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:05.662934   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:05.662995   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:05.694743   97653 logs.go:274] 0 containers: []
W0810 15:48:05.694763   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:05.694818   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:05.726462   97653 logs.go:274] 0 containers: []
W0810 15:48:05.726476   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:05.726542   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:05.758608   97653 logs.go:274] 0 containers: []
W0810 15:48:05.758622   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:05.758684   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:05.790085   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:05.790106   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:05.790115   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:05.834941   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:05.834952   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:05.917660   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:05.917672   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:05.937307   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:05.937320   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:06.015163   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:06.015187   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:06.055064   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:06.055075   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:06.160331   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:06.160349   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:06.223932   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:06.223943   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:06.248151   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:06.248162   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:08.777914   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:08.782428   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:08.994191   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:09.118266   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:09.118353   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:09.163565   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:09.163688   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:09.203106   97653 logs.go:274] 0 containers: []
W0810 15:48:09.203120   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:09.203174   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:09.244347   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:09.244402   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:09.277359   97653 logs.go:274] 0 containers: []
W0810 15:48:09.277375   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:09.277448   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:09.311004   97653 logs.go:274] 0 containers: []
W0810 15:48:09.311014   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:09.311062   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:09.345279   97653 logs.go:274] 0 containers: []
W0810 15:48:09.345291   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:09.345347   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:09.378164   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:09.378193   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:09.378200   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:09.420523   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:09.420536   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:09.470199   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:09.470212   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:09.518051   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:09.518064   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:09.607795   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:09.607807   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:09.688487   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:09.688498   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:09.800647   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:09.800660   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:09.824802   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:09.824822   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:09.853616   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:09.853636   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:12.372941   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:12.394597   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:12.493971   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:12.557092   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:12.557153   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:12.591294   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:12.591372   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:12.627361   97653 logs.go:274] 0 containers: []
W0810 15:48:12.627372   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:12.627425   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:12.661036   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:12.661114   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:12.694785   97653 logs.go:274] 0 containers: []
W0810 15:48:12.694798   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:12.694843   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:12.730211   97653 logs.go:274] 0 containers: []
W0810 15:48:12.730234   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:12.730333   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:12.764468   97653 logs.go:274] 0 containers: []
W0810 15:48:12.764483   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:12.764537   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:12.800056   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:12.800085   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:12.800096   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:12.900169   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:12.900181   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:12.941276   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:12.941296   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:12.988498   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:12.988512   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:13.105244   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:13.105265   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:13.154213   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:13.154228   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:13.240176   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:13.240189   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:13.259630   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:13.259643   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:13.283358   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:13.283369   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:15.811768   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:15.825137   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:15.993319   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:16.033958   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:16.034013   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:16.067021   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:16.067079   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:16.098789   97653 logs.go:274] 0 containers: []
W0810 15:48:16.098802   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:16.098868   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:16.130540   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:16.130599   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:16.161976   97653 logs.go:274] 0 containers: []
W0810 15:48:16.161988   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:16.162039   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:16.193535   97653 logs.go:274] 0 containers: []
W0810 15:48:16.193557   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:16.193618   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:16.225206   97653 logs.go:274] 0 containers: []
W0810 15:48:16.225216   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:16.225268   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:16.257321   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:16.257355   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:16.257372   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:16.342432   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:16.342444   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:16.424256   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:16.424274   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:16.447863   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:16.447874   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:16.467075   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:16.467086   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:16.505464   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:16.505475   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:16.551669   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:16.551680   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:16.659710   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:16.659722   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:16.705045   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:16.705056   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:19.233747   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:19.247977   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:19.493607   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:19.602639   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:19.602730   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:19.636846   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:19.636935   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:19.669677   97653 logs.go:274] 0 containers: []
W0810 15:48:19.669687   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:19.669753   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:19.709397   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:19.709452   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:19.742309   97653 logs.go:274] 0 containers: []
W0810 15:48:19.742320   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:19.742366   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:19.774637   97653 logs.go:274] 0 containers: []
W0810 15:48:19.774647   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:19.774702   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:19.806878   97653 logs.go:274] 0 containers: []
W0810 15:48:19.806897   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:19.806948   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:19.841238   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:19.841258   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:19.841265   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:19.927491   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:19.927503   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:20.007160   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:20.007180   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:20.046445   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:20.046461   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:20.070706   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:20.070719   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:20.090913   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:20.090930   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:20.137645   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:20.137657   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:20.250805   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:20.250819   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:20.296277   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:20.296290   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:22.827067   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:22.830791   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:22.994478   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:23.062755   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:23.062806   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:23.094680   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:23.094744   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:23.126119   97653 logs.go:274] 0 containers: []
W0810 15:48:23.126129   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:23.126181   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:23.158609   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:23.158674   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:23.190193   97653 logs.go:274] 0 containers: []
W0810 15:48:23.190203   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:23.190251   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:23.223235   97653 logs.go:274] 0 containers: []
W0810 15:48:23.223250   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:23.223298   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:23.254784   97653 logs.go:274] 0 containers: []
W0810 15:48:23.254796   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:23.254876   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:23.294938   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:23.294983   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:23.294998   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:23.317794   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:23.317819   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:23.425254   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:23.425270   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:23.471346   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:23.471367   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:23.494705   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:23.494717   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:23.522695   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:23.522708   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:23.610967   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:23.610981   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:23.698637   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:23.698650   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:23.737264   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:23.737276   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:26.281554   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:26.287476   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:26.494086   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:26.660407   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:26.660463   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:26.706618   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:26.706672   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:26.758627   97653 logs.go:274] 0 containers: []
W0810 15:48:26.758643   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:26.758690   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:26.812547   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:26.812618   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:26.860573   97653 logs.go:274] 0 containers: []
W0810 15:48:26.860586   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:26.860648   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:26.901687   97653 logs.go:274] 0 containers: []
W0810 15:48:26.901698   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:26.901758   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:26.937460   97653 logs.go:274] 0 containers: []
W0810 15:48:26.937473   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:26.937533   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:26.973679   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:26.973700   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:26.973716   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:27.089602   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:27.089614   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:27.141244   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:27.141256   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:27.319865   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:27.319885   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:27.404089   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:27.404108   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:27.470761   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:27.470777   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:27.612209   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:27.612221   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:27.631622   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:27.631634   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:27.672813   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:27.672824   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:30.197053   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:30.210299   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:30.210500   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0810 15:48:30.262312   97653 logs.go:274] 1 containers: [9a063eb44f07]
I0810 15:48:30.262364   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0810 15:48:30.294066   97653 logs.go:274] 1 containers: [7f18a0a769cb]
I0810 15:48:30.294139   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0810 15:48:30.325245   97653 logs.go:274] 0 containers: []
W0810 15:48:30.325258   97653 logs.go:276] No container was found matching "coredns"
I0810 15:48:30.325308   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0810 15:48:30.361615   97653 logs.go:274] 1 containers: [d93466df0653]
I0810 15:48:30.361666   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0810 15:48:30.394745   97653 logs.go:274] 0 containers: []
W0810 15:48:30.394757   97653 logs.go:276] No container was found matching "kube-proxy"
I0810 15:48:30.394802   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0810 15:48:30.429379   97653 logs.go:274] 0 containers: []
W0810 15:48:30.429401   97653 logs.go:276] No container was found matching "kubernetes-dashboard"
I0810 15:48:30.429447   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0810 15:48:30.463001   97653 logs.go:274] 0 containers: []
W0810 15:48:30.463014   97653 logs.go:276] No container was found matching "storage-provisioner"
I0810 15:48:30.463073   97653 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0810 15:48:30.518236   97653 logs.go:274] 1 containers: [6d16409166db]
I0810 15:48:30.518264   97653 logs.go:123] Gathering logs for kubelet ...
I0810 15:48:30.518273   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0810 15:48:30.628697   97653 logs.go:123] Gathering logs for etcd [7f18a0a769cb] ...
I0810 15:48:30.628710   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7f18a0a769cb"
I0810 15:48:30.673775   97653 logs.go:123] Gathering logs for kube-scheduler [d93466df0653] ...
I0810 15:48:30.673787   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d93466df0653"
I0810 15:48:30.791261   97653 logs.go:123] Gathering logs for kube-controller-manager [6d16409166db] ...
I0810 15:48:30.791276   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6d16409166db"
I0810 15:48:30.836372   97653 logs.go:123] Gathering logs for container status ...
I0810 15:48:30.836384   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0810 15:48:30.863948   97653 logs.go:123] Gathering logs for dmesg ...
I0810 15:48:30.863960   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0810 15:48:30.883235   97653 logs.go:123] Gathering logs for describe nodes ...
I0810 15:48:30.883248   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0810 15:48:30.960810   97653 logs.go:123] Gathering logs for kube-apiserver [9a063eb44f07] ...
I0810 15:48:30.960823   97653 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9a063eb44f07"
I0810 15:48:31.000075   97653 logs.go:123] Gathering logs for Docker ...
I0810 15:48:31.000087   97653 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0810 15:48:33.523801   97653 api_server.go:240] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0810 15:48:33.548472   97653 api_server.go:256] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
I0810 15:48:33.564082   97653 out.go:177] 
W0810 15:48:33.580940   97653 out.go:239] ‚ùå  Exiting due to GUEST_START: wait 6m0s for node: wait for healthy API server: apiserver healthz never reported healthy: timed out waiting for the condition
W0810 15:48:33.581055   97653 out.go:239] 
W0810 15:48:33.588362   97653 out.go:239] [31m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    üòø  If the above advice does not help, please let us know:                             [31m‚îÇ[0m
[31m‚îÇ[0m    üëâ  https://github.com/kubernetes/minikube/issues/new/choose                           [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
I0810 15:48:33.609824   97653 out.go:177] 

* 
* ==> Docker <==
* -- Logs begin at Wed 2022-08-10 12:37:35 UTC, end at Wed 2022-08-10 12:52:45 UTC. --
Aug 10 12:37:43 minikube systemd[1]: Starting Docker Application Container Engine...
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.619071038Z" level=info msg="Starting up"
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.620953451Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.620978346Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.621025219Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.621043404Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.622170543Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.622202388Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.622234443Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.622253636Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.651868999Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.723012308Z" level=warning msg="Your kernel does not support CPU realtime scheduler"
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.723083776Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.723107168Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Aug 10 12:37:43 minikube dockerd[871]: time="2022-08-10T12:37:43.723556118Z" level=info msg="Loading containers: start."
Aug 10 12:37:44 minikube dockerd[871]: time="2022-08-10T12:37:44.154257495Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Aug 10 12:37:44 minikube dockerd[871]: time="2022-08-10T12:37:44.295730754Z" level=info msg="Loading containers: done."
Aug 10 12:37:44 minikube dockerd[871]: time="2022-08-10T12:37:44.322841579Z" level=info msg="Docker daemon" commit=a89b842 graphdriver(s)=overlay2 version=20.10.17
Aug 10 12:37:44 minikube dockerd[871]: time="2022-08-10T12:37:44.322927573Z" level=info msg="Daemon has completed initialization"
Aug 10 12:37:44 minikube systemd[1]: Started Docker Application Container Engine.
Aug 10 12:37:44 minikube dockerd[871]: time="2022-08-10T12:37:44.353065981Z" level=info msg="API listen on [::]:2376"
Aug 10 12:37:44 minikube dockerd[871]: time="2022-08-10T12:37:44.359189301Z" level=info msg="API listen on /var/run/docker.sock"
Aug 10 12:38:12 minikube dockerd[871]: time="2022-08-10T12:38:12.494914457Z" level=info msg="ignoring event" container=baf75a377906276ea2c7c721eabf0d08fbcac09b9916d2203865ed54441b74d1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:38:35 minikube dockerd[871]: time="2022-08-10T12:38:35.806739375Z" level=info msg="ignoring event" container=f3eed7bcd0742e6cbc3e7e92a9acb245c06e80a43252e87720286c8e0158a640 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:38:45 minikube dockerd[871]: time="2022-08-10T12:38:45.794267595Z" level=info msg="ignoring event" container=d2d87260b87b32ace0587668257c3928bc8831ff9b4b6ee205071b33be54bca8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:39:19 minikube dockerd[871]: time="2022-08-10T12:39:19.192805610Z" level=info msg="ignoring event" container=ebcc50d3fc1c286c1288e8422438ac52a522bb54c7af4522c11d5ed306c6f794 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:40:17 minikube dockerd[871]: time="2022-08-10T12:40:17.954221300Z" level=info msg="ignoring event" container=055b04b411b4cbc0af53a3986fd2107ca446560c3ea426fffadd9d09a04817e4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:41:52 minikube dockerd[871]: time="2022-08-10T12:41:52.213957578Z" level=info msg="ignoring event" container=b71f80a30798668a007925ef497ceb1b2ada6a6898d0c493adb94886e6d470a3 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:41:58 minikube dockerd[871]: time="2022-08-10T12:41:58.526394341Z" level=info msg="ignoring event" container=044ef07ebf31f8071344c940e0c47c7255ea52046dd7c053ddd401dd9de87fd8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:41:58 minikube dockerd[871]: time="2022-08-10T12:41:58.937321270Z" level=info msg="ignoring event" container=f4723e770dcd04ccdaade0941f90f03222bbf37d5574ef5a1bba6b1510128801 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:41:59 minikube dockerd[871]: time="2022-08-10T12:41:59.181966701Z" level=info msg="ignoring event" container=2d11838897ed6b7d2e78fa97054a2d1a41b607de4497cd85ea1569b94253c793 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:41:59 minikube dockerd[871]: time="2022-08-10T12:41:59.600553453Z" level=info msg="ignoring event" container=5585719eb654ce42f976319e77881594196235c3d35121af7e2fb5f21f4c4c5e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:41:59 minikube dockerd[871]: time="2022-08-10T12:41:59.865505619Z" level=info msg="ignoring event" container=9ebf54d3821bbe3cd45eb3b6bb952cb464b442d17899f44f1b6037148bad3e16 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:00 minikube dockerd[871]: time="2022-08-10T12:42:00.302560651Z" level=info msg="ignoring event" container=34af7a9f768d787ad07bbe9cf3e795e512dd89151c4f98d9f540c814529e1b52 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:00 minikube dockerd[871]: time="2022-08-10T12:42:00.579953839Z" level=info msg="ignoring event" container=49fc3235448e9f571fe4585c5cf193110164bdbc51689f8d6d9c049df66c0f2a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:01 minikube dockerd[871]: time="2022-08-10T12:42:01.030083260Z" level=info msg="ignoring event" container=2afc98d741d0f7492f62794dd64eebde0e3c5a8bba96478b50e794d47ca528b0 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:01 minikube dockerd[871]: time="2022-08-10T12:42:01.263088209Z" level=info msg="ignoring event" container=da21ead61ec08e2a131e865b86fce8533b33dc9865dd7f16fac43fc555ff147a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:01 minikube dockerd[871]: time="2022-08-10T12:42:01.817150904Z" level=info msg="ignoring event" container=7ab4d3868c5a84b0d41b6c808724bdbaaa1156cbc5424b478955bdb071302c29 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:02 minikube dockerd[871]: time="2022-08-10T12:42:02.176747870Z" level=info msg="ignoring event" container=addaad21f66a5fd20849d73fbfbd0f1ea0aee6bc6e5dfbcf32d233b38142a70b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:02 minikube dockerd[871]: time="2022-08-10T12:42:02.618287054Z" level=info msg="ignoring event" container=67ebcd47a6de50687820d09d8e1239b14de7282f33e9e97d1b7f0fb418a32ed8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:02 minikube dockerd[871]: time="2022-08-10T12:42:02.989189064Z" level=info msg="ignoring event" container=b90b934856092c1603473ad5e2f45ffc3c4d4bcfe63b2c056e25f8002d32590f module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:03 minikube dockerd[871]: time="2022-08-10T12:42:03.346129050Z" level=info msg="ignoring event" container=1299fd43701de54193c235bd9927e4a7209a0217da5d8022872daa5e3cc8e78c module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:03 minikube dockerd[871]: time="2022-08-10T12:42:03.738467788Z" level=info msg="ignoring event" container=24f704ac1dfd17bf4505f13b34042e4b436a6034b02b73930bd453800c0abc93 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:04 minikube dockerd[871]: time="2022-08-10T12:42:04.135100187Z" level=info msg="ignoring event" container=b53428705176c25f38f32001bae36f07a3ee8ae486c0bda88746ef4316b2eea0 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:04 minikube dockerd[871]: time="2022-08-10T12:42:04.505748675Z" level=info msg="ignoring event" container=d8d70a512d29cf7633746f415ebc09489767c23895a7ecf9213d85ef9efc1023 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:05 minikube dockerd[871]: time="2022-08-10T12:42:05.115550056Z" level=info msg="ignoring event" container=66bb003ef97ec1eae622b1320577350781c9bbea0de0cd0c7161d577667c3d6e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:05 minikube dockerd[871]: time="2022-08-10T12:42:05.372875384Z" level=info msg="ignoring event" container=ed32d4ff48298a95ebf17a741f40175f9d8ba1b538edc240032e81d3d7b40d11 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:05 minikube dockerd[871]: time="2022-08-10T12:42:05.805467473Z" level=info msg="ignoring event" container=8765a4c12559923d2fb458c41040a4d47d0d724aadfbdd0400cbdd7d1e843939 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:06 minikube dockerd[871]: time="2022-08-10T12:42:06.170119018Z" level=info msg="ignoring event" container=bcbd1fa7ef0dd1a1e59a11c8c903bf27ed0a168cd211baa1865f3fca29bcecf4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:06 minikube dockerd[871]: time="2022-08-10T12:42:06.370539117Z" level=info msg="ignoring event" container=76d81a43ce829d4d55df31002a29060793bb288976ac2f96ae5025fc07b3bbf4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:06 minikube dockerd[871]: time="2022-08-10T12:42:06.676359479Z" level=info msg="ignoring event" container=669ab3c7955ab803ec7f5d95df096bdab7e6848480e14b4e98e17587e6175dab module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:06 minikube dockerd[871]: time="2022-08-10T12:42:06.950077867Z" level=info msg="ignoring event" container=49d69558a8420d747069cad262e9a8f26cd67817ab6eed446821afe35cfc42bf module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:07 minikube dockerd[871]: time="2022-08-10T12:42:07.276014048Z" level=info msg="ignoring event" container=848d7f966f1828740ef281360f947dc42913122443798c4ec7065f74a17fa40d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:30 minikube dockerd[871]: time="2022-08-10T12:42:30.296417702Z" level=info msg="ignoring event" container=135d5d8705caffc06a6b9e0b8e3e7f0792c4bb08cc112ddd974bdf441e951dae module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:42:42 minikube dockerd[871]: time="2022-08-10T12:42:42.397164096Z" level=info msg="ignoring event" container=3e0cecbc0c4cbb22e7e719a1f8c4db5dd1c3f1668a7199efe8a3674b851f6238 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:43:13 minikube dockerd[871]: time="2022-08-10T12:43:13.798286296Z" level=info msg="ignoring event" container=3c3769ef5143dc320b2262c0540d965d6ecc230302f9f838de7761be9f7166a1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:43:49 minikube dockerd[871]: time="2022-08-10T12:43:49.029244416Z" level=info msg="ignoring event" container=ff4656d4f9e3012c23d871fdd7aa6e983d92653c6308d183dd9d66f2cb9831fa module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:44:47 minikube dockerd[871]: time="2022-08-10T12:44:47.956642499Z" level=info msg="ignoring event" container=89e097edd23d6789cbe69dee1a7494a3b1ce6690ff281c4d4648d5a396878eee module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:46:20 minikube dockerd[871]: time="2022-08-10T12:46:20.787566825Z" level=info msg="ignoring event" container=6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Aug 10 12:49:15 minikube dockerd[871]: time="2022-08-10T12:49:15.284693469Z" level=info msg="ignoring event" container=c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
c70d8615325bb       586c112956dfc       3 minutes ago       Exited              kube-controller-manager   6                   4e6e9e99f766a
7f18a0a769cb6       aebe758cef4cd       10 minutes ago      Running             etcd                      0                   060336ba9367e
d93466df0653d       3a5aa3a515f5d       10 minutes ago      Running             kube-scheduler            0                   3c95fc91e382d
9a063eb44f07b       d521dd763e2e3       10 minutes ago      Running             kube-apiserver            0                   21fb7c92b0bea

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=62e108c3dfdec8029a890ad6d8ef96b6461426dc
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2022_08_10T15_42_25_0700
                    minikube.k8s.io/version=v1.26.1
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Wed, 10 Aug 2022 12:42:20 +0000
Taints:             node.kubernetes.io/not-ready:NoSchedule
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 10 Aug 2022 12:52:40 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 10 Aug 2022 12:47:43 +0000   Wed, 10 Aug 2022 12:42:14 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 10 Aug 2022 12:47:43 +0000   Wed, 10 Aug 2022 12:42:14 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 10 Aug 2022 12:47:43 +0000   Wed, 10 Aug 2022 12:42:14 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 10 Aug 2022 12:47:43 +0000   Wed, 10 Aug 2022 12:42:35 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  49430096Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             8020252Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  49430096Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             8020252Ki
  pods:               110
System Info:
  Machine ID:                 4c192b04687c403f8fbb9bc7975b21b3
  System UUID:                ac13bd38-478a-4e66-860a-e4f6f1cecd12
  Boot ID:                    ad764a14-8656-49ac-b0a7-d028df8ebe00
  Kernel Version:             5.15.0-43-generic
  OS Image:                   Ubuntu 20.04.4 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.17
  Kubelet Version:            v1.24.3
  Kube-Proxy Version:         v1.24.3
Non-terminated Pods:          (4 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 etcd-minikube                       100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (1%!)(MISSING)       0 (0%!)(MISSING)         10m
  kube-system                 kube-apiserver-minikube             250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 kube-controller-manager-minikube    200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 kube-scheduler-minikube             100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                650m (16%!)(MISSING)  0 (0%!)(MISSING)
  memory             100Mi (1%!)(MISSING)  0 (0%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From     Message
  ----    ------                   ----               ----     -------
  Normal  NodeHasSufficientMemory  10m (x7 over 10m)  kubelet  Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    10m (x6 over 10m)  kubelet  Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     10m (x6 over 10m)  kubelet  Node minikube status is now: NodeHasSufficientPID
  Normal  Starting                 10m                kubelet  Starting kubelet.
  Normal  NodeHasSufficientMemory  10m                kubelet  Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    10m                kubelet  Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     10m                kubelet  Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  10m                kubelet  Updated Node Allocatable limit across pods
  Normal  NodeReady                10m                kubelet  Node minikube status is now: NodeReady

* 
* ==> dmesg <==
* [  +0.004735] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.001355] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.001657] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.000007] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.000664] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.002352] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.005555] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.000960] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.000896] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.002078] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[  +0.000391] iwlwifi 0000:02:00.0: Fail start Tx agg on tid: 0
[Aug10 12:07] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[ +10.532524] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.892387] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.730774] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.469059] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.817880] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.876780] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +5.424840] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[Aug10 12:08] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.704997] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +5.173184] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.499425] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.858999] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.859537] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[ +15.961086] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.843941] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.780694] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.861925] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.516782] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.745836] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.773276] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.779226] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.957655] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.513985] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.890758] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.758340] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[Aug10 12:09] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.800172] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +6.024947] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.879523] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.775715] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.909819] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +6.157127] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.053277] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.890641] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.779610] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.532784] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.787407] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.887602] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.786090] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.016416] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +8.353231] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.902368] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.797704] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.794901] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.533804] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[Aug10 12:10] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +1.754292] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...
[  +2.529472] iwlwifi 0000:02:00.0: No beacon heard and the time event is over already...

* 
* ==> etcd [7f18a0a769cb] <==
* {"level":"info","ts":"2022-08-10T12:42:14.364Z","caller":"etcdserver/server.go:2531","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2022-08-10T12:42:14.364Z","caller":"etcdserver/server.go:2042","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2022-08-10T12:42:14.364Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-08-10T12:42:14.372Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-08-10T12:42:14.379Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2022-08-10T12:42:14.379Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2022-08-10T12:42:14.382Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2022-08-10T12:42:14.390Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2022-08-10T12:43:33.280Z","caller":"traceutil/trace.go:171","msg":"trace[1589925336] transaction","detail":"{read_only:false; response_revision:302; number_of_response:1; }","duration":"237.853189ms","start":"2022-08-10T12:43:33.042Z","end":"2022-08-10T12:43:33.280Z","steps":["trace[1589925336] 'process raft request'  (duration: 231.26072ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:44:53.256Z","caller":"traceutil/trace.go:171","msg":"trace[1082068127] transaction","detail":"{read_only:false; response_revision:358; number_of_response:1; }","duration":"220.372469ms","start":"2022-08-10T12:44:53.035Z","end":"2022-08-10T12:44:53.255Z","steps":["trace[1082068127] 'process raft request'  (duration: 208.904275ms)","trace[1082068127] 'compare'  (duration: 11.119175ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:45:53.279Z","caller":"traceutil/trace.go:171","msg":"trace[1510706456] linearizableReadLoop","detail":"{readStateIndex:427; appliedIndex:426; }","duration":"113.066522ms","start":"2022-08-10T12:45:53.166Z","end":"2022-08-10T12:45:53.279Z","steps":["trace[1510706456] 'read index received'  (duration: 101.718728ms)","trace[1510706456] 'applied index is now lower than readState.Index'  (duration: 11.347289ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:45:53.279Z","caller":"traceutil/trace.go:171","msg":"trace[1298467803] transaction","detail":"{read_only:false; response_revision:371; number_of_response:1; }","duration":"212.418523ms","start":"2022-08-10T12:45:53.067Z","end":"2022-08-10T12:45:53.279Z","steps":["trace[1298467803] 'process raft request'  (duration: 201.095004ms)","trace[1298467803] 'compare'  (duration: 11.216477ms)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:45:53.281Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"113.236436ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/networkpolicies/\" range_end:\"/registry/networkpolicies0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2022-08-10T12:45:53.281Z","caller":"traceutil/trace.go:171","msg":"trace[204728744] range","detail":"{range_begin:/registry/networkpolicies/; range_end:/registry/networkpolicies0; response_count:0; response_revision:371; }","duration":"114.862015ms","start":"2022-08-10T12:45:53.166Z","end":"2022-08-10T12:45:53.281Z","steps":["trace[204728744] 'agreement among raft nodes before linearized reading'  (duration: 113.1715ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:45:58.539Z","caller":"traceutil/trace.go:171","msg":"trace[900171022] linearizableReadLoop","detail":"{readStateIndex:428; appliedIndex:428; }","duration":"149.57033ms","start":"2022-08-10T12:45:58.389Z","end":"2022-08-10T12:45:58.538Z","steps":["trace[900171022] 'read index received'  (duration: 149.564196ms)","trace[900171022] 'applied index is now lower than readState.Index'  (duration: 5.3¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:45:58.547Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"158.400658ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/minions/\" range_end:\"/registry/minions0\" limit:500 ","response":"range_response_count:1 size:4684"}
{"level":"info","ts":"2022-08-10T12:45:58.547Z","caller":"traceutil/trace.go:171","msg":"trace[399608581] range","detail":"{range_begin:/registry/minions/; range_end:/registry/minions0; response_count:1; response_revision:371; }","duration":"158.470945ms","start":"2022-08-10T12:45:58.389Z","end":"2022-08-10T12:45:58.547Z","steps":["trace[399608581] 'agreement among raft nodes before linearized reading'  (duration: 149.675281ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:46:13.274Z","caller":"traceutil/trace.go:171","msg":"trace[2078573961] transaction","detail":"{read_only:false; response_revision:376; number_of_response:1; }","duration":"215.719321ms","start":"2022-08-10T12:46:13.058Z","end":"2022-08-10T12:46:13.274Z","steps":["trace[2078573961] 'process raft request'  (duration: 206.92711ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:47:28.659Z","caller":"traceutil/trace.go:171","msg":"trace[1463944568] linearizableReadLoop","detail":"{readStateIndex:468; appliedIndex:468; }","duration":"110.783837ms","start":"2022-08-10T12:47:28.548Z","end":"2022-08-10T12:47:28.659Z","steps":["trace[1463944568] 'read index received'  (duration: 110.7644ms)","trace[1463944568] 'applied index is now lower than readState.Index'  (duration: 16.424¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:47:28.668Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"120.040038ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2022-08-10T12:47:28.668Z","caller":"traceutil/trace.go:171","msg":"trace[661427075] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:393; }","duration":"120.323891ms","start":"2022-08-10T12:47:28.548Z","end":"2022-08-10T12:47:28.668Z","steps":["trace[661427075] 'agreement among raft nodes before linearized reading'  (duration: 111.150118ms)"],"step_count":1}
{"level":"warn","ts":"2022-08-10T12:47:28.668Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"114.059657ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2022-08-10T12:47:28.669Z","caller":"traceutil/trace.go:171","msg":"trace[1858958273] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:393; }","duration":"114.70166ms","start":"2022-08-10T12:47:28.554Z","end":"2022-08-10T12:47:28.669Z","steps":["trace[1858958273] 'agreement among raft nodes before linearized reading'  (duration: 105.369937ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:47:43.222Z","caller":"traceutil/trace.go:171","msg":"trace[294371018] linearizableReadLoop","detail":"{readStateIndex:475; appliedIndex:475; }","duration":"174.579383ms","start":"2022-08-10T12:47:43.048Z","end":"2022-08-10T12:47:43.222Z","steps":["trace[294371018] 'read index received'  (duration: 174.558028ms)","trace[294371018] 'applied index is now lower than readState.Index'  (duration: 18.037¬µs)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:47:43.225Z","caller":"traceutil/trace.go:171","msg":"trace[1839893923] transaction","detail":"{read_only:false; response_revision:398; number_of_response:1; }","duration":"123.178251ms","start":"2022-08-10T12:47:43.102Z","end":"2022-08-10T12:47:43.225Z","steps":["trace[1839893923] 'process raft request'  (duration: 120.892075ms)"],"step_count":1}
{"level":"warn","ts":"2022-08-10T12:47:43.225Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"177.217831ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/default\" ","response":"range_response_count:1 size:343"}
{"level":"info","ts":"2022-08-10T12:47:43.225Z","caller":"traceutil/trace.go:171","msg":"trace[374145653] range","detail":"{range_begin:/registry/namespaces/default; range_end:; response_count:1; response_revision:397; }","duration":"177.616072ms","start":"2022-08-10T12:47:43.048Z","end":"2022-08-10T12:47:43.225Z","steps":["trace[374145653] 'agreement among raft nodes before linearized reading'  (duration: 174.889219ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:47:53.273Z","caller":"traceutil/trace.go:171","msg":"trace[1614963186] transaction","detail":"{read_only:false; response_revision:400; number_of_response:1; }","duration":"218.466797ms","start":"2022-08-10T12:47:53.054Z","end":"2022-08-10T12:47:53.273Z","steps":["trace[1614963186] 'process raft request'  (duration: 209.281099ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:47:53.273Z","caller":"traceutil/trace.go:171","msg":"trace[745091731] transaction","detail":"{read_only:false; response_revision:401; number_of_response:1; }","duration":"113.715642ms","start":"2022-08-10T12:47:53.159Z","end":"2022-08-10T12:47:53.273Z","steps":["trace[745091731] 'process raft request'  (duration: 113.534741ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:47:58.700Z","caller":"traceutil/trace.go:171","msg":"trace[2129921607] linearizableReadLoop","detail":"{readStateIndex:483; appliedIndex:483; }","duration":"162.105627ms","start":"2022-08-10T12:47:58.537Z","end":"2022-08-10T12:47:58.700Z","steps":["trace[2129921607] 'read index received'  (duration: 162.091546ms)","trace[2129921607] 'applied index is now lower than readState.Index'  (duration: 12.858¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:47:58.708Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"170.799052ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2022-08-10T12:47:58.708Z","caller":"traceutil/trace.go:171","msg":"trace[1316318832] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:401; }","duration":"170.871968ms","start":"2022-08-10T12:47:58.537Z","end":"2022-08-10T12:47:58.708Z","steps":["trace[1316318832] 'agreement among raft nodes before linearized reading'  (duration: 162.214751ms)"],"step_count":1}
{"level":"warn","ts":"2022-08-10T12:47:58.708Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"170.62403ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2022-08-10T12:47:58.708Z","caller":"traceutil/trace.go:171","msg":"trace[1149719721] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:401; }","duration":"170.798311ms","start":"2022-08-10T12:47:58.538Z","end":"2022-08-10T12:47:58.708Z","steps":["trace[1149719721] 'agreement among raft nodes before linearized reading'  (duration: 162.133774ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:49:23.302Z","caller":"traceutil/trace.go:171","msg":"trace[129808837] transaction","detail":"{read_only:false; response_revision:421; number_of_response:1; }","duration":"223.545077ms","start":"2022-08-10T12:49:23.079Z","end":"2022-08-10T12:49:23.302Z","steps":["trace[129808837] 'process raft request'  (duration: 206.888013ms)","trace[129808837] 'compare'  (duration: 16.3155ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:50:37.780Z","caller":"traceutil/trace.go:171","msg":"trace[76850893] linearizableReadLoop","detail":"{readStateIndex:549; appliedIndex:549; }","duration":"156.886975ms","start":"2022-08-10T12:50:37.623Z","end":"2022-08-10T12:50:37.780Z","steps":["trace[76850893] 'read index received'  (duration: 156.877771ms)","trace[76850893] 'applied index is now lower than readState.Index'  (duration: 7.736¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:50:37.789Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"165.540015ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/limitranges/\" range_end:\"/registry/limitranges0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2022-08-10T12:50:37.789Z","caller":"traceutil/trace.go:171","msg":"trace[1664978898] range","detail":"{range_begin:/registry/limitranges/; range_end:/registry/limitranges0; response_count:0; response_revision:436; }","duration":"165.598507ms","start":"2022-08-10T12:50:37.623Z","end":"2022-08-10T12:50:37.789Z","steps":["trace[1664978898] 'agreement among raft nodes before linearized reading'  (duration: 156.992967ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:50:43.284Z","caller":"traceutil/trace.go:171","msg":"trace[212730795] transaction","detail":"{read_only:false; response_revision:437; number_of_response:1; }","duration":"220.12139ms","start":"2022-08-10T12:50:43.064Z","end":"2022-08-10T12:50:43.284Z","steps":["trace[212730795] 'process raft request'  (duration: 208.375067ms)","trace[212730795] 'compare'  (duration: 11.51731ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:50:43.284Z","caller":"traceutil/trace.go:171","msg":"trace[1290975615] linearizableReadLoop","detail":"{readStateIndex:552; appliedIndex:551; }","duration":"127.422533ms","start":"2022-08-10T12:50:43.157Z","end":"2022-08-10T12:50:43.284Z","steps":["trace[1290975615] 'read index received'  (duration: 115.611817ms)","trace[1290975615] 'applied index is now lower than readState.Index'  (duration: 11.808126ms)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:50:43.285Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"127.828014ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/roles/\" range_end:\"/registry/roles0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2022-08-10T12:50:43.285Z","caller":"traceutil/trace.go:171","msg":"trace[1795663398] range","detail":"{range_begin:/registry/roles/; range_end:/registry/roles0; response_count:0; response_revision:437; }","duration":"128.376906ms","start":"2022-08-10T12:50:43.157Z","end":"2022-08-10T12:50:43.285Z","steps":["trace[1795663398] 'agreement among raft nodes before linearized reading'  (duration: 127.647211ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:50:53.288Z","caller":"traceutil/trace.go:171","msg":"trace[293434672] transaction","detail":"{read_only:false; response_revision:439; number_of_response:1; }","duration":"222.341773ms","start":"2022-08-10T12:50:53.065Z","end":"2022-08-10T12:50:53.288Z","steps":["trace[293434672] 'process raft request'  (duration: 207.890772ms)","trace[293434672] 'compare'  (duration: 14.354138ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:50:58.020Z","caller":"traceutil/trace.go:171","msg":"trace[1292960848] linearizableReadLoop","detail":"{readStateIndex:557; appliedIndex:557; }","duration":"204.315562ms","start":"2022-08-10T12:50:57.815Z","end":"2022-08-10T12:50:58.020Z","steps":["trace[1292960848] 'read index received'  (duration: 204.290242ms)","trace[1292960848] 'applied index is now lower than readState.Index'  (duration: 20.042¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:50:58.031Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"215.488084ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/rolebindings/\" range_end:\"/registry/rolebindings0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2022-08-10T12:50:58.031Z","caller":"traceutil/trace.go:171","msg":"trace[889981858] range","detail":"{range_begin:/registry/rolebindings/; range_end:/registry/rolebindings0; response_count:0; response_revision:440; }","duration":"215.612387ms","start":"2022-08-10T12:50:57.815Z","end":"2022-08-10T12:50:58.031Z","steps":["trace[889981858] 'agreement among raft nodes before linearized reading'  (duration: 204.727573ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:51:03.290Z","caller":"traceutil/trace.go:171","msg":"trace[961438900] transaction","detail":"{read_only:false; response_revision:441; number_of_response:1; }","duration":"216.207693ms","start":"2022-08-10T12:51:03.074Z","end":"2022-08-10T12:51:03.290Z","steps":["trace[961438900] 'process raft request'  (duration: 207.321266ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:51:08.276Z","caller":"traceutil/trace.go:171","msg":"trace[518707751] linearizableReadLoop","detail":"{readStateIndex:561; appliedIndex:561; }","duration":"196.633992ms","start":"2022-08-10T12:51:08.079Z","end":"2022-08-10T12:51:08.276Z","steps":["trace[518707751] 'read index received'  (duration: 196.616363ms)","trace[518707751] 'applied index is now lower than readState.Index'  (duration: 14.424¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:51:08.278Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"199.449473ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/deployments/\" range_end:\"/registry/deployments0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2022-08-10T12:51:08.279Z","caller":"traceutil/trace.go:171","msg":"trace[1551953282] range","detail":"{range_begin:/registry/deployments/; range_end:/registry/deployments0; response_count:0; response_revision:442; }","duration":"199.610867ms","start":"2022-08-10T12:51:08.079Z","end":"2022-08-10T12:51:08.279Z","steps":["trace[1551953282] 'agreement among raft nodes before linearized reading'  (duration: 196.86974ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:51:13.285Z","caller":"traceutil/trace.go:171","msg":"trace[352100679] transaction","detail":"{read_only:false; response_revision:443; number_of_response:1; }","duration":"217.093658ms","start":"2022-08-10T12:51:13.067Z","end":"2022-08-10T12:51:13.285Z","steps":["trace[352100679] 'process raft request'  (duration: 211.041118ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:51:28.502Z","caller":"traceutil/trace.go:171","msg":"trace[113393377] transaction","detail":"{read_only:false; response_revision:446; number_of_response:1; }","duration":"186.314808ms","start":"2022-08-10T12:51:28.315Z","end":"2022-08-10T12:51:28.501Z","steps":["trace[113393377] 'process raft request'  (duration: 174.884439ms)","trace[113393377] 'compare'  (duration: 11.188794ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:51:33.278Z","caller":"traceutil/trace.go:171","msg":"trace[360472048] transaction","detail":"{read_only:false; response_revision:447; number_of_response:1; }","duration":"218.298768ms","start":"2022-08-10T12:51:33.059Z","end":"2022-08-10T12:51:33.278Z","steps":["trace[360472048] 'process raft request'  (duration: 209.812988ms)"],"step_count":1}
{"level":"info","ts":"2022-08-10T12:51:53.284Z","caller":"traceutil/trace.go:171","msg":"trace[1616965532] transaction","detail":"{read_only:false; response_revision:451; number_of_response:1; }","duration":"223.705302ms","start":"2022-08-10T12:51:53.060Z","end":"2022-08-10T12:51:53.284Z","steps":["trace[1616965532] 'process raft request'  (duration: 209.033462ms)","trace[1616965532] 'compare'  (duration: 14.582361ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:52:03.291Z","caller":"traceutil/trace.go:171","msg":"trace[357322849] transaction","detail":"{read_only:false; response_revision:453; number_of_response:1; }","duration":"219.430059ms","start":"2022-08-10T12:52:03.072Z","end":"2022-08-10T12:52:03.291Z","steps":["trace[357322849] 'process raft request'  (duration: 207.751207ms)","trace[357322849] 'compare'  (duration: 11.486886ms)"],"step_count":2}
{"level":"info","ts":"2022-08-10T12:52:14.642Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":391}
{"level":"info","ts":"2022-08-10T12:52:14.646Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":391,"took":"3.1646ms"}
{"level":"info","ts":"2022-08-10T12:52:40.819Z","caller":"traceutil/trace.go:171","msg":"trace[758358525] linearizableReadLoop","detail":"{readStateIndex:600; appliedIndex:600; }","duration":"204.953227ms","start":"2022-08-10T12:52:40.614Z","end":"2022-08-10T12:52:40.819Z","steps":["trace[758358525] 'read index received'  (duration: 204.928817ms)","trace[758358525] 'applied index is now lower than readState.Index'  (duration: 19.615¬µs)"],"step_count":2}
{"level":"warn","ts":"2022-08-10T12:52:40.821Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"207.580832ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/kube-system/kube-controller-manager-minikube.1709fc5118027ea9\" ","response":"range_response_count:1 size:719"}
{"level":"info","ts":"2022-08-10T12:52:40.822Z","caller":"traceutil/trace.go:171","msg":"trace[696619348] range","detail":"{range_begin:/registry/events/kube-system/kube-controller-manager-minikube.1709fc5118027ea9; range_end:; response_count:1; response_revision:461; }","duration":"208.138569ms","start":"2022-08-10T12:52:40.614Z","end":"2022-08-10T12:52:40.822Z","steps":["trace[696619348] 'agreement among raft nodes before linearized reading'  (duration: 205.196053ms)"],"step_count":1}

* 
* ==> kernel <==
*  12:52:45 up  7:24,  0 users,  load average: 1.92, 1.84, 1.92
Linux minikube 5.15.0-43-generic #46~20.04.1-Ubuntu SMP Thu Jul 14 15:20:17 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.4 LTS"

* 
* ==> kube-apiserver [9a063eb44f07] <==
* W0810 12:42:17.029026       1 genericapiserver.go:557] Skipping API apps/v1beta2 because it has no resources.
W0810 12:42:17.029046       1 genericapiserver.go:557] Skipping API apps/v1beta1 because it has no resources.
W0810 12:42:17.032717       1 genericapiserver.go:557] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
I0810 12:42:17.039729       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I0810 12:42:17.039758       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W0810 12:42:17.086003       1 genericapiserver.go:557] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I0810 12:42:20.234821       1 secure_serving.go:210] Serving securely on [::]:8443
I0810 12:42:20.234980       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0810 12:42:20.235071       1 apf_controller.go:317] Starting API Priority and Fairness config controller
I0810 12:42:20.235128       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0810 12:42:20.235266       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0810 12:42:20.240177       1 autoregister_controller.go:141] Starting autoregister controller
I0810 12:42:20.240218       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0810 12:42:20.240445       1 controller.go:83] Starting OpenAPI AggregationController
I0810 12:42:20.240682       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I0810 12:42:20.240831       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0810 12:42:20.254346       1 available_controller.go:491] Starting AvailableConditionController
I0810 12:42:20.254366       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0810 12:42:20.254401       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0810 12:42:20.268461       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0810 12:42:20.268594       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0810 12:42:20.269008       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0810 12:42:20.269021       1 shared_informer.go:255] Waiting for caches to sync for cluster_authentication_trust_controller
I0810 12:42:20.269505       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0810 12:42:20.305170       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0810 12:42:20.305451       1 shared_informer.go:255] Waiting for caches to sync for crd-autoregister
I0810 12:42:20.306318       1 controller.go:85] Starting OpenAPI controller
I0810 12:42:20.306672       1 controller.go:85] Starting OpenAPI V3 controller
I0810 12:42:20.306922       1 naming_controller.go:291] Starting NamingConditionController
I0810 12:42:20.307118       1 establishing_controller.go:76] Starting EstablishingController
I0810 12:42:20.307322       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0810 12:42:20.307490       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0810 12:42:20.307701       1 crd_finalizer.go:266] Starting CRDFinalizer
I0810 12:42:20.311718       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0810 12:42:20.334076       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0810 12:42:20.469114       1 shared_informer.go:262] Caches are synced for cluster_authentication_trust_controller
I0810 12:42:20.488326       1 shared_informer.go:262] Caches are synced for node_authorizer
I0810 12:42:20.493766       1 apf_controller.go:322] Running API Priority and Fairness config worker
I0810 12:42:20.507696       1 shared_informer.go:262] Caches are synced for crd-autoregister
I0810 12:42:20.540286       1 cache.go:39] Caches are synced for autoregister controller
I0810 12:42:20.555111       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0810 12:42:20.572596       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0810 12:42:20.580959       1 controller.go:611] quota admission added evaluator for: namespaces
I0810 12:42:20.581511       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0810 12:42:21.279726       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0810 12:42:21.288048       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0810 12:42:21.288437       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0810 12:42:22.748336       1 controller.go:611] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0810 12:42:22.878041       1 controller.go:611] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0810 12:42:23.053505       1 alloc.go:327] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W0810 12:42:23.104771       1 lease.go:234] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I0810 12:42:23.106724       1 controller.go:611] quota admission added evaluator for: endpoints
I0810 12:42:23.116876       1 controller.go:611] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0810 12:42:24.950305       1 controller.go:611] quota admission added evaluator for: serviceaccounts
I0810 12:42:24.962095       1 controller.go:611] quota admission added evaluator for: deployments.apps
I0810 12:42:24.995773       1 alloc.go:327] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I0810 12:42:25.016598       1 controller.go:611] quota admission added evaluator for: daemonsets.apps
I0810 12:42:25.162549       1 controller.go:611] quota admission added evaluator for: leases.coordination.k8s.io
I0810 12:44:27.449968       1 alloc.go:327] "allocated clusterIPs" service="kubernetes-dashboard/kubernetes-dashboard" clusterIPs=map[IPv4:10.103.82.9]
I0810 12:44:27.515838       1 alloc.go:327] "allocated clusterIPs" service="kubernetes-dashboard/dashboard-metrics-scraper" clusterIPs=map[IPv4:10.111.41.192]

* 
* ==> kube-controller-manager [c70d8615325b] <==
* 
goroutine 138 [select]:
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil(0x0?, {0x4cfe020, 0xc000a6d5c0}, 0x1, 0xc000114300)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:167 +0x135
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil(0x0?, 0xdf8475800, 0x0, 0x0?, 0x0?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133 +0x89
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.Until(0x0?, 0x0?, 0x0?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:90 +0x25
created by k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicServingCertificateController).Run
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/tlsconfig.go:250 +0x24a

goroutine 140 [sync.Cond.Wait]:
sync.runtime_notifyListWait(0xc000479e10, 0x0)
	/usr/local/go/src/runtime/sema.go:513 +0x13d
sync.(*Cond).Wait(0x4d0ce90?)
	/usr/local/go/src/sync/cond.go:56 +0x8c
k8s.io/kubernetes/vendor/k8s.io/client-go/util/workqueue.(*Type).Get(0xc00029a000)
	vendor/k8s.io/client-go/util/workqueue/queue.go:157 +0x9e
k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicFileCAContent).processNextWorkItem(0xc00029a1e0)
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/dynamic_cafile_content.go:225 +0x58
k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicFileCAContent).runWorker(0xc0004c06a0?)
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/dynamic_cafile_content.go:220 +0x25
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1(0x0?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:155 +0x3e
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil(0x68dd20?, {0x4cfe020, 0xc000f99a10}, 0x1, 0xc0001143c0)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:156 +0xb6
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil(0xc000142008?, 0x3b9aca00, 0x0, 0xd0?, 0xc0004aaf60?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133 +0x89
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.Until(0x0?, 0xc0004ba600?, 0x0?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:90 +0x25
created by k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicFileCAContent).Run
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/dynamic_cafile_content.go:161 +0x298

goroutine 141 [select]:
k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicFileCAContent).watchCAFile(0xc00029a1e0, 0xc0001143c0)
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/dynamic_cafile_content.go:190 +0x2f6
k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicFileCAContent).Run.func1()
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/dynamic_cafile_content.go:165 +0x3c
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1(0x30?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:155 +0x3e
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil(0x0?, {0x4cfe020, 0xc000a6d7a0}, 0x1, 0xc0001143c0)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:156 +0xb6
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil(0x0?, 0xdf8475800, 0x0, 0x1?, 0x442505?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:133 +0x89
k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.Until(0x4d21fa0?, 0xc000202780?, 0x0?)
	vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:90 +0x25
created by k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/dynamiccertificates.(*DynamicFileCAContent).Run
	vendor/k8s.io/apiserver/pkg/server/dynamiccertificates/dynamic_cafile_content.go:164 +0x372

goroutine 142 [syscall]:
syscall.Syscall6(0xe8, 0xe, 0xc0010afc14, 0x7, 0xffffffffffffffff, 0x0, 0x0)
	/usr/local/go/src/syscall/asm_linux_amd64.s:43 +0x5
k8s.io/kubernetes/vendor/golang.org/x/sys/unix.EpollWait(0x0?, {0xc0010afc14?, 0x0?, 0x0?}, 0x0?)
	vendor/golang.org/x/sys/unix/zsyscall_linux_amd64.go:56 +0x58
k8s.io/kubernetes/vendor/github.com/fsnotify/fsnotify.(*fdPoller).wait(0xc000a70bc0)
	vendor/github.com/fsnotify/fsnotify/inotify_poller.go:86 +0x7d
k8s.io/kubernetes/vendor/github.com/fsnotify/fsnotify.(*Watcher).readEvents(0xc0004acd20)
	vendor/github.com/fsnotify/fsnotify/inotify.go:192 +0x26e
created by k8s.io/kubernetes/vendor/github.com/fsnotify/fsnotify.NewWatcher
	vendor/github.com/fsnotify/fsnotify/inotify.go:59 +0x1c5

* 
* ==> kube-scheduler [d93466df0653] <==
* W0810 12:51:13.335507       1 reflector.go:324] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:13.335692       1 reflector.go:138] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:24.351019       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:24.351520       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:25.783870       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:25.783987       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:28.180107       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:28.180235       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:31.671500       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:31.671737       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:32.069161       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:32.069193       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:32.207961       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:32.208023       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:34.565366       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:34.565491       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:36.802698       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:36.802801       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:37.021123       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:37.021246       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:38.192381       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:38.192413       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:40.994029       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:40.994184       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:41.249744       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:41.249852       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:51.663825       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:51.663961       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:51:56.586751       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:51:56.586850       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:03.506881       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:03.507102       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:11.509673       1 reflector.go:324] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:11.509902       1 reflector.go:138] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:12.524728       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:12.524914       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:16.682602       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:16.682982       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:21.225347       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:21.225563       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:24.016062       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:24.016239       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:26.768605       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:26.768792       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:27.204619       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:27.204826       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:27.335078       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:27.335256       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:27.523927       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:27.524082       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:29.235517       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:29.235736       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:31.831098       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:31.831303       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:34.517558       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:34.517671       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:37.645165       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:37.645237       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
W0810 12:52:38.963545       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2
E0810 12:52:38.963889       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": x509: certificate is valid for 192.168.58.2, 10.96.0.1, 127.0.0.1, 10.0.0.1, not 192.168.49.2

* 
* ==> kubelet <==
* -- Logs begin at Wed 2022-08-10 12:37:35 UTC, end at Wed 2022-08-10 12:52:46 UTC. --
Aug 10 12:46:42 minikube kubelet[17516]: I0810 12:46:42.536232   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:46:42 minikube kubelet[17516]: E0810 12:46:42.539746   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:46:53 minikube kubelet[17516]: I0810 12:46:53.541347   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:46:53 minikube kubelet[17516]: E0810 12:46:53.544491   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:47:04 minikube kubelet[17516]: I0810 12:47:04.536508   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:47:04 minikube kubelet[17516]: E0810 12:47:04.538691   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:47:19 minikube kubelet[17516]: I0810 12:47:19.538990   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:47:19 minikube kubelet[17516]: E0810 12:47:19.543819   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:47:34 minikube kubelet[17516]: I0810 12:47:34.535258   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:47:34 minikube kubelet[17516]: E0810 12:47:34.536178   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:47:48 minikube kubelet[17516]: I0810 12:47:48.535880   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:47:48 minikube kubelet[17516]: E0810 12:47:48.536715   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:48:02 minikube kubelet[17516]: I0810 12:48:02.536580   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:48:02 minikube kubelet[17516]: E0810 12:48:02.537507   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:48:16 minikube kubelet[17516]: I0810 12:48:16.536418   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:48:16 minikube kubelet[17516]: E0810 12:48:16.536871   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:48:28 minikube kubelet[17516]: I0810 12:48:28.536853   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:48:28 minikube kubelet[17516]: E0810 12:48:28.541070   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:48:40 minikube kubelet[17516]: I0810 12:48:40.536780   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:48:40 minikube kubelet[17516]: E0810 12:48:40.539036   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:48:52 minikube kubelet[17516]: I0810 12:48:52.536468   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:48:52 minikube kubelet[17516]: E0810 12:48:52.539689   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:49:03 minikube kubelet[17516]: I0810 12:49:03.536727   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:49:15 minikube kubelet[17516]: I0810 12:49:15.968603   17516 scope.go:110] "RemoveContainer" containerID="6d16409166dbc7c1e74e5a04b9f2e271169736abd8487a44b7c3f0d55d254ca6"
Aug 10 12:49:15 minikube kubelet[17516]: I0810 12:49:15.969021   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:49:15 minikube kubelet[17516]: E0810 12:49:15.969562   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:49:17 minikube kubelet[17516]: I0810 12:49:17.981047   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:49:17 minikube kubelet[17516]: E0810 12:49:17.984207   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:49:23 minikube kubelet[17516]: I0810 12:49:23.841184   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:49:23 minikube kubelet[17516]: E0810 12:49:23.844356   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:49:37 minikube kubelet[17516]: I0810 12:49:37.545499   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:49:37 minikube kubelet[17516]: E0810 12:49:37.555702   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:49:49 minikube kubelet[17516]: I0810 12:49:49.543304   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:49:49 minikube kubelet[17516]: E0810 12:49:49.546376   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:50:00 minikube kubelet[17516]: I0810 12:50:00.538529   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:50:00 minikube kubelet[17516]: E0810 12:50:00.543054   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:50:11 minikube kubelet[17516]: I0810 12:50:11.536148   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:50:11 minikube kubelet[17516]: E0810 12:50:11.538443   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:50:24 minikube kubelet[17516]: I0810 12:50:24.537233   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:50:24 minikube kubelet[17516]: E0810 12:50:24.539095   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:50:37 minikube kubelet[17516]: I0810 12:50:37.536206   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:50:37 minikube kubelet[17516]: E0810 12:50:37.537291   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:50:52 minikube kubelet[17516]: I0810 12:50:52.536386   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:50:52 minikube kubelet[17516]: E0810 12:50:52.538482   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:51:04 minikube kubelet[17516]: I0810 12:51:04.536550   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:51:04 minikube kubelet[17516]: E0810 12:51:04.539834   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:51:19 minikube kubelet[17516]: I0810 12:51:19.536753   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:51:19 minikube kubelet[17516]: E0810 12:51:19.539100   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:51:31 minikube kubelet[17516]: I0810 12:51:31.553835   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:51:31 minikube kubelet[17516]: E0810 12:51:31.562870   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:51:42 minikube kubelet[17516]: I0810 12:51:42.537031   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:51:42 minikube kubelet[17516]: E0810 12:51:42.538668   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:51:57 minikube kubelet[17516]: I0810 12:51:57.537340   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:51:57 minikube kubelet[17516]: E0810 12:51:57.541972   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:52:12 minikube kubelet[17516]: I0810 12:52:12.536874   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:52:12 minikube kubelet[17516]: E0810 12:52:12.540474   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:52:25 minikube kubelet[17516]: I0810 12:52:25.537497   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:52:25 minikube kubelet[17516]: E0810 12:52:25.540301   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e
Aug 10 12:52:40 minikube kubelet[17516]: I0810 12:52:40.537327   17516 scope.go:110] "RemoveContainer" containerID="c70d8615325bbde15249c17aa58a1da0fcc01f8c9fb7554aab2f9e49b642eeba"
Aug 10 12:52:40 minikube kubelet[17516]: E0810 12:52:40.547955   17516 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(76444121a189d8a30add20fb32ab6d4e)\"" pod="kube-system/kube-controller-manager-minikube" podUID=76444121a189d8a30add20fb32ab6d4e

